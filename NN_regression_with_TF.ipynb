{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN regression with TF",
      "provenance": [],
      "collapsed_sections": [
        "cXCYzVvcqJab",
        "BLVWqIKnruDk",
        "CoL48vKisFUV",
        "JaHhHuVm67wR",
        "8T2aaLyN9RAr",
        "H7J_rbwhNKE6",
        "hzweKnf3KH3n",
        "VJOxkNPlK8ar",
        "sMPuuIxmNTVl",
        "HEYGXwUsP1jq",
        "17HYRD6zRt2q",
        "NXK1S1ybVw7d",
        "S31i19njYK_5",
        "09AvcoR9YeR7",
        "gKOpMmn_a5x0",
        "cZngn7GJ3gId",
        "sTS8pg__3lrI",
        "liONSUem4KIP",
        "mv_R1W-6Fpqr",
        "a5UbzTp3GXHM"
      ],
      "authorship_tag": "ABX9TyNCNBlwB+2DiTsi1D6uR7Qz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manudwd/Classification--preprocessing-data-/blob/main/NN_regression_with_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtmpyllRznIC"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeUIVln9z8IL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbJ0cPg0E10"
      },
      "source": [
        "creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "8AwAKb-d0Msd",
        "outputId": "99f2a042-0977-42bb-f3ae-49a70d18d5d9"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "#create some features\n",
        "X=np.array([-7.0,-4.0,-1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "#create some labels labels are marked by lower case letters\n",
        "y=np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
        "\n",
        "#plot the data \n",
        "plt.scatter(X,y) #for scatter plot\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3c4e6f2310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0HYWQNL1exr",
        "outputId": "9e5b6ff9-afc6-4059-f707-38c5d3d47502"
      },
      "source": [
        "y==X+10 #is the relationship we're trying to establish between the features and the labels\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfq4yXf01m49"
      },
      "source": [
        "#Input and ouput shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J74TV6wh1pU5"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "So heres the thing, understanding data and how you're going to implment is equally important. Here we only need a single value of X to predict y value at that coordinate.\n",
        "\n",
        "Thus the single value of this numpy array, is scalar value, which ahs  a dimension of 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7X2-a7UJ29tW",
        "outputId": "34cb6b53-6e48-4cb7-84c5-660cf9cfc760"
      },
      "source": [
        "#converting the numpy array into a tensor while changing dtype\n",
        "X=tf.cast(tf.constant(X),dtype=tf.float32)\n",
        "y=tf.cast(tf.constant(y),dtype=tf.float32)\n",
        "X,y\n",
        "\n",
        "inputshape=X[0].shape\n",
        "outputshape=y[0].shape\n",
        "inputshape, outputshape\n",
        "\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3c4e6f2210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx8wV0bN3_U4"
      },
      "source": [
        "# Steps to modeeling in tensor flow\n",
        "1. Creating a model to define input and outputs and hidden layeres of the deep learning model.\n",
        "2. Compiling model-define the loss function(essentially how wrong our model is) and the optimizer(tell our model how to improve its performace) and the evaluation matrix (aka hwo to interpret the model)\n",
        "3.Fitting a mdoel-letting th model try to find patterns between X &y (features and labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrbVxyWB8shG"
      },
      "source": [
        "you can use model.add to add layers as well as \n",
        "the method below, point is that tehre are mutiple ways to do hte same thing \n",
        "in tensor flow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEQYpVre4buZ",
        "outputId": "b3907a95-d5c5-44f4-fdbb-315ead62c0e3"
      },
      "source": [
        "#setting the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1 create the model using seqeuntial API \n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        " #Sequential provides training and inference features\n",
        "#here we have added them in a list\n",
        "\n",
        "\n",
        "#the number is 1 because we are taking 1 from feature and comparing it with 1 label\n",
        "#2. compile the model\n",
        "\n",
        "#loss is how wrongn your model's prediction are compared to the truth labels\n",
        "#we attempt to minimise this \n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])#metrics is a human interpretable value for \n",
        "                              #how well your model is  doing\n",
        "\n",
        "\n",
        "#alot of the times you if some function like mae has shortcut names\n",
        "#you can simply use the string value as done in the metrics field\n",
        "#for example you can simply write optimizer=[\"SGD\"] and it would work\n",
        "\n",
        "\n",
        "#3 fit the model\n",
        "model.fit(X,y, epochs=5) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4e6a6450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mskrMoTa7eBg"
      },
      "source": [
        "what this says that we have a lose of 10.9748 at the end when trying to fit our y values for X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg475u_9A087",
        "outputId": "e110c888-9ad8-4549-8763-8ed08b666455"
      },
      "source": [
        "#predicting our model\n",
        "model.predict([17.0])+10\n",
        "\n",
        "#our model here doesn't correctly fit the assumptions \n",
        "#thus it requires optimization \n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.71602]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IatTZYroFGh"
      },
      "source": [
        "#Improving our NN model\n",
        "\n",
        "altering how we went through the creation compiling and  fitting stage of the model\n",
        "\n",
        "1. creating a model- we might add more layers and increase the number of neuron / the hidden layers. and change the activation function of each la yer.\n",
        "2. Compiling a model- we might change the optimization function or perhaps the learning rate of the optimization funciton\n",
        "3. We might fit our model for more epochs or on more given data(more modells or examples of data to learn from)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jol9WdlNo0Dl",
        "outputId": "b2adea8b-ab74-4ec9-e045-644d69fab726"
      },
      "source": [
        "#we might start with a smaller model and move into a larger model\n",
        "\n",
        "#create the mode\n",
        "model=tf.keras.Sequential([\n",
        "                     tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "           optimizer=tf.keras.optimizers.SGD(),\n",
        "           metrics=[\"mae\"])\n",
        "\n",
        "#3.fit the model\n",
        "model.fit(X, y, epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4e58ef90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXCYzVvcqJab"
      },
      "source": [
        "#1Here we see that by changing a single hyperparameter we changed the mae to aprox 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dsR6m8VqSM2",
        "outputId": "c6347eef-c9a5-4e46-a7e4-25b160d28b8b"
      },
      "source": [
        "#predicting the data\n",
        "model.predict([17.0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXyHRTIFqoUw",
        "outputId": "2446b9d9-987a-42aa-9a68-872f2f31ac29"
      },
      "source": [
        "#now lets try to change further parameters in our NN\n",
        "\n",
        "#create the model\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(100, activation=None ),\n",
        "                           tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#fit the model\n",
        "model.fit(X,y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 293ms/step - loss: 12.0109 - mae: 12.0109\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.5402 - mae: 11.5402\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.0604 - mae: 11.0604\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5690 - mae: 10.5690\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0635 - mae: 10.0635\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5413 - mae: 9.5413\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9998 - mae: 8.9998\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4362 - mae: 8.4362\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8475 - mae: 7.8475\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2898 - mae: 7.2898\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2707 - mae: 7.2707\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2516 - mae: 7.2516\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2325 - mae: 7.2325\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2133 - mae: 7.2133\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1941 - mae: 7.1941\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1749 - mae: 7.1749\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1556 - mae: 7.1556\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1362 - mae: 7.1362\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1168 - mae: 7.1168\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0974 - mae: 7.0974\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0778 - mae: 7.0778\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0583 - mae: 7.0583\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0386 - mae: 7.0386\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0189 - mae: 7.0189\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9991 - mae: 6.9991\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9792 - mae: 6.9792\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9592 - mae: 6.9592\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9392 - mae: 6.9392\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9191 - mae: 6.9191\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8988 - mae: 6.8988\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8785 - mae: 6.8785\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8581 - mae: 6.8581\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8376 - mae: 6.8376\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8170 - mae: 6.8170\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.7963 - mae: 6.7963\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7755 - mae: 6.7755\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7545 - mae: 6.7545\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7335 - mae: 6.7335\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7123 - mae: 6.7123\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6910 - mae: 6.6910\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6696 - mae: 6.6696\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.6480 - mae: 6.6480\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6263 - mae: 6.6263\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6045 - mae: 6.6045\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.5876 - mae: 6.5876\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5798 - mae: 6.5798\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5582 - mae: 6.5582\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5363 - mae: 6.5363\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.5144 - mae: 6.5144\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.4922 - mae: 6.4922\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4700 - mae: 6.4700\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4475 - mae: 6.4475\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4249 - mae: 6.4249\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4021 - mae: 6.4021\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3792 - mae: 6.3792\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3560 - mae: 6.3560\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3327 - mae: 6.3327\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3092 - mae: 6.3092\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2855 - mae: 6.2855\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2616 - mae: 6.2616\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2375 - mae: 6.2375\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2132 - mae: 6.2132\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1887 - mae: 6.1887\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1785 - mae: 6.1785\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1639 - mae: 6.1639\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1393 - mae: 6.1393\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1146 - mae: 6.1146\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0896 - mae: 6.0896\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0644 - mae: 6.0644\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0390 - mae: 6.0390\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0133 - mae: 6.0133\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9874 - mae: 5.9874\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9612 - mae: 5.9612\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9348 - mae: 5.9348\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.9081 - mae: 5.9081\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8812 - mae: 5.8812\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8540 - mae: 5.8540\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8265 - mae: 5.8265\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.7988 - mae: 5.7988\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7961 - mae: 5.7961\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7717 - mae: 5.7717\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7437 - mae: 5.7437\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7155 - mae: 5.7155\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.6869 - mae: 5.6869\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6581 - mae: 5.6581\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6290 - mae: 5.6290\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5995 - mae: 5.5995\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5697 - mae: 5.5697\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5396 - mae: 5.5396\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5092 - mae: 5.5092\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4785 - mae: 5.4785\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4474 - mae: 5.4474\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4160 - mae: 5.4160\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4091 - mae: 5.4091\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3850 - mae: 5.3850\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3532 - mae: 5.3532\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3210 - mae: 5.3210\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2884 - mae: 5.2884\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2555 - mae: 5.2555\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2221 - mae: 5.2221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4d4a0290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLVWqIKnruDk"
      },
      "source": [
        "#now the loss is 3.699 reduced even further"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfCNxmS-r04X",
        "outputId": "525709ad-ef8c-4903-e4eb-24f13c1815c3"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.61856]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoL48vKisFUV"
      },
      "source": [
        "#here we find out that adding extra layers actually reduced the accuracy of the model, this is in line with the prediction on AxelNet where increasin the number of parameters,accumulators,hidden layers actually decrease the accuracy\n",
        "\n",
        "We can conclude here that the model is overfitting over the data, and is deriving from previous values too well, ie just relating to what it already knows. so at the end, the error we get isn't a real valid representation of what it is doing. \n",
        "\n",
        "So remember that the real efficieny/accuracy we get from our model is not through the training data, but through data it has never seen before\n",
        "\n",
        "ALSO, decreasing the number of nuerons or the hidden nodes further decays the prediciton values. This is however, as expected\n",
        "\n",
        "\n",
        "#another important finding is that upon chaning the activation to none, the prediction values improved, thought the mae loss increased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DF3r6_ZsWRR",
        "outputId": "267744db-3cda-40bc-d980-981e1cc2969d"
      },
      "source": [
        "#lets further try to make changes to the model again\n",
        "#this time changing the optimizer\n",
        "\n",
        "#1. create the model\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "                           tf.keras.layers.Dense(1)\n",
        "])\n",
        "#2. compile the model\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "              metrics=[\"mae\"])\n",
        "#3.fit the mdoel\n",
        "model.fit(X,y,epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 12.7339 - mae: 12.7339\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.7255 - mae: 12.7255\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.7171 - mae: 12.7171\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.7087 - mae: 12.7087\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.7003 - mae: 12.7003\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.6919 - mae: 12.6919\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.6750 - mae: 12.6750\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6666 - mae: 12.6666\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6582 - mae: 12.6582\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6498 - mae: 12.6498\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.6415 - mae: 12.6415\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.6331 - mae: 12.6331\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.6248 - mae: 12.6248\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.6164 - mae: 12.6164\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.6080 - mae: 12.6080\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5996 - mae: 12.5996\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.5912 - mae: 12.5912\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5828 - mae: 12.5828\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5745 - mae: 12.5745\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5661 - mae: 12.5661\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.5577 - mae: 12.5577\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.5493 - mae: 12.5493\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5409 - mae: 12.5409\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.5326 - mae: 12.5326\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.5242 - mae: 12.5242\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.5158 - mae: 12.5158\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.5074 - mae: 12.5074\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4990 - mae: 12.4990\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4907 - mae: 12.4907\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.4823 - mae: 12.4823\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4739 - mae: 12.4739\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4656 - mae: 12.4656\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.4572 - mae: 12.4572\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.4488 - mae: 12.4488\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.4404 - mae: 12.4404\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4321 - mae: 12.4321\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.4237 - mae: 12.4237\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4153 - mae: 12.4153\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4069 - mae: 12.4069\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3986 - mae: 12.3986\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3902 - mae: 12.3902\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3818 - mae: 12.3818\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3734 - mae: 12.3734\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.3650 - mae: 12.3650\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3567 - mae: 12.3567\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3483 - mae: 12.3483\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.3399 - mae: 12.3399\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3315 - mae: 12.3315\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3231 - mae: 12.3231\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.3147 - mae: 12.3147\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.3063 - mae: 12.3063\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2979 - mae: 12.2979\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.2895 - mae: 12.2895\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2811 - mae: 12.2811\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.2727 - mae: 12.2727\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.2643 - mae: 12.2643\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2559 - mae: 12.2559\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.2475 - mae: 12.2475\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2391 - mae: 12.2391\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.2307 - mae: 12.2307\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.2223 - mae: 12.2223\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.2139 - mae: 12.2139\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2055 - mae: 12.2055\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.1971 - mae: 12.1971\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1886 - mae: 12.1886\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1802 - mae: 12.1802\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1718 - mae: 12.1718\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1634 - mae: 12.1634\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1550 - mae: 12.1550\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1465 - mae: 12.1465\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.1381 - mae: 12.1381\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1297 - mae: 12.1297\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1213 - mae: 12.1213\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.1128 - mae: 12.1128\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1044 - mae: 12.1044\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0960 - mae: 12.0960\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0876 - mae: 12.0876\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0791 - mae: 12.0791\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0707 - mae: 12.0707\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0623 - mae: 12.0623\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0538 - mae: 12.0538\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0454 - mae: 12.0454\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0370 - mae: 12.0370\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0285 - mae: 12.0285\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0201 - mae: 12.0201\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0116 - mae: 12.0116\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0032 - mae: 12.0032\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9947 - mae: 11.9947\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9863 - mae: 11.9863\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9778 - mae: 11.9778\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9694 - mae: 11.9694\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9610 - mae: 11.9610\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9525 - mae: 11.9525\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.9441 - mae: 11.9441\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9356 - mae: 11.9356\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9272 - mae: 11.9272\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9188 - mae: 11.9188\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.9103 - mae: 11.9103\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.9019 - mae: 11.9019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4c3a72d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqjR3wJVtm8i"
      },
      "source": [
        "Here we have another weird finding where introducing the adam optimizer with lr=0.0001 actually hindrerd the loss as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZkSnlZmtwgn",
        "outputId": "52634141-6038-4e52-8ba4-d5a77d6cec1a"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.625799]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4COkScB0t0ZI"
      },
      "source": [
        "this shows that all otpimizations isn't good otpimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5LCWWE6t4pm",
        "outputId": "a382c8ab-5103-4df9-f157-96a6c5ba4675"
      },
      "source": [
        "#lets try another model change\n",
        "#its good practice to keep adding smaller changes to your model to understand \n",
        "#what works for model and what doesn't, this practice of incremental change \n",
        "#will lead to an overall good model\n",
        "#lets further try to make changes to the model again\n",
        "#this time changing the optimizer\n",
        "\n",
        "#1. create the model\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "                           tf.keras.layers.Dense(1)\n",
        "])\n",
        "#2. compile the model\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "#3.fit the mdoel\n",
        "model.fit(X,y,epochs=100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 328ms/step - loss: 13.0842 - mae: 13.0842\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.1504 - mae: 12.1504\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1886 - mae: 11.1886\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2381 - mae: 10.2381\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.4843 - mae: 9.4843\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7138 - mae: 8.7138\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9227 - mae: 7.9227\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1122 - mae: 7.1122\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2750 - mae: 6.2750\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4108 - mae: 5.4108\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5219 - mae: 4.5219\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8833 - mae: 3.8833\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8054 - mae: 3.8054\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9588 - mae: 3.9588\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2295 - mae: 4.2295\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5052 - mae: 4.5052\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6686 - mae: 4.6686\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7343 - mae: 4.7343\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7149 - mae: 4.7149\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6219 - mae: 4.6219\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4664 - mae: 4.4664\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2582 - mae: 4.2582\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0064 - mae: 4.0064\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7310 - mae: 3.7310\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5995 - mae: 3.5995\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4702 - mae: 3.4702\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3395 - mae: 3.3395\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2598 - mae: 3.2598\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2927 - mae: 3.2927\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3002 - mae: 3.3002\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2770 - mae: 3.2770\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2215 - mae: 3.2215\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1343 - mae: 3.1343\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0158 - mae: 3.0158\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9140 - mae: 2.9140\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8970 - mae: 2.8970\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8638 - mae: 2.8638\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8118 - mae: 2.8118\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7434 - mae: 2.7434\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6590 - mae: 2.6590\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5638 - mae: 2.5638\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4555 - mae: 2.4555\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3828 - mae: 2.3828\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3095 - mae: 2.3095\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1862 - mae: 2.1862\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0937 - mae: 2.0937\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0172 - mae: 2.0172\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9205 - mae: 1.9205\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8052 - mae: 1.8052\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6714 - mae: 1.6714\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5148 - mae: 1.5148\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3914 - mae: 1.3914\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2517 - mae: 1.2517\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0757 - mae: 1.0757\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9719 - mae: 0.9719\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7562 - mae: 0.7562\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6041 - mae: 0.6041\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4304 - mae: 0.4304\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2734 - mae: 0.2734\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2558 - mae: 0.2558\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2742 - mae: 0.2742\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2676 - mae: 0.2676\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6551 - mae: 0.6551\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4409 - mae: 0.4409\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6201 - mae: 0.6201\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7156 - mae: 0.7156\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5028 - mae: 0.5028\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7208 - mae: 0.7208\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7545 - mae: 0.7545\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4114 - mae: 0.4114\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4665 - mae: 0.4665\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4411 - mae: 0.4411\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2620 - mae: 0.2620\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2111 - mae: 0.2111\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2251 - mae: 0.2251\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2488 - mae: 0.2488\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1861 - mae: 0.1861\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2253 - mae: 0.2253\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1798 - mae: 0.1798\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1981 - mae: 0.1981\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2149 - mae: 0.2149\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2630 - mae: 0.2630\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2599 - mae: 0.2599\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2308 - mae: 0.2308\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1811 - mae: 0.1811\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1468 - mae: 0.1468\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1304 - mae: 0.1304\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2069 - mae: 0.2069\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1287 - mae: 0.1287\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0980 - mae: 0.0980\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2207 - mae: 0.2207\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0973 - mae: 0.0973\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1141 - mae: 0.1141\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2021 - mae: 0.2021\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1712 - mae: 0.1712\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2179 - mae: 0.2179\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2456 - mae: 0.2456\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1454 - mae: 0.1454\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1170 - mae: 0.1170\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2210 - mae: 0.2210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4b240610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgr32alx6th-",
        "outputId": "5114db93-f562-41fb-e200-addaf87bbb83"
      },
      "source": [
        "#chaning the learning rate to 0.01 made the best possible change so far\n",
        "#with mae=0.16 lets check our predicted values\n",
        "model.predict([17.0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c4c3a4830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[27.846497]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA6TIbFe7Kom"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaHhHuVm67wR"
      },
      "source": [
        "This gave the best possible result for our model so far\n",
        "#the learning rate is possibly the most important hyperparameter in your NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6zaeeip7UtE"
      },
      "source": [
        "#now lets try fitting more data, ie creating a larger data set\n",
        "#Or try fitting for even longer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2WFcAZc7gek"
      },
      "source": [
        "Now let's try evaluating the model\n",
        "aka how well has it learned the relationships between the features and the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK5FTIMf7spo"
      },
      "source": [
        "#in practice, a typical work flow is the same as what we just did\n",
        "#we fit the model and tweak it and evaluate until it fits the desired status\n",
        "\n",
        "#All you have to do is learn to visualize what your model is doing to evaluate it\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro6fhVyI72Pr"
      },
      "source": [
        "We may visualize the data\n",
        "-the data-what its doing\n",
        "-the model itself what does it look like\n",
        "the training of the model-how does it perform while its learns\n",
        "-prediciton of mode-how the prediction line up with the truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc4z-_bA8omk",
        "outputId": "6a74b512-5564-4eeb-fed4-c8783c07886e"
      },
      "source": [
        "#lets now try to mkae a bigger data set\n",
        "\n",
        "X=tf.range(-100,100,4) #creating no btw -100 and 100 with a step of 4\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0quk1mdw8-S9",
        "outputId": "f9abb7ac-5cd2-4f45-fa1f-20ce6d39d5be"
      },
      "source": [
        "#now we make the labels we want our model to learn\n",
        "y=X+10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gTXDlmZy9C_7",
        "outputId": "e6b94907-e23a-4732-fa78-66ade7342f82"
      },
      "source": [
        "#now visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3c498f5750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T2aaLyN9RAr"
      },
      "source": [
        "#three sets concept\n",
        "\n",
        "#basically we split our data into training and test sets\n",
        "1.training set- the model learns from this data, whihc is typically 70-80% of the total data available.\n",
        "2. validation set- the model gets tuned from this data, 10-15% of the data \n",
        "3. Test set- the model gets evaluated on t his data to test what it has learned this set is typically 10-15% of the total data available\n",
        "\n",
        "usually we get rid of validation set if we remove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDs-1u51Lmmm",
        "outputId": "7fcd60b0-204b-4b42-d6aa-b7961741cc2a"
      },
      "source": [
        "#check the length of data which we have \n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoGJ6QWjL9Hb",
        "outputId": "47e2c2c8-5962-40ba-b6e5-1231ea4b78e4"
      },
      "source": [
        "#split the data into train and test set\n",
        "X_train=X[:40] #firstt 40 sets \n",
        "y_train=y[:40]\n",
        "X_test=X[40:] #last 40 sets 20% of the data\n",
        "y_test=y[40:]\n",
        "\n",
        "len(X_train),len(y_train),len(X_test),len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 40, 10, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7J_rbwhNKE6"
      },
      "source": [
        "#visualizing  the data\n",
        "Now we've got the data in training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "fkfEMzrHNOvP",
        "outputId": "22047efb-0671-4f5c-85a2-387cfcfd2a21"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "#plot training data\n",
        "plt.scatter(X_train,y_train,c=\"b\",label=\"testing data\")\n",
        "#plot testing data\n",
        "plt.scatter(X_test,y_test,c=\"g\",label=\"testing data\")\n",
        "#show a legend\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3c49864f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5txOoiavGga9"
      },
      "source": [
        "#create the model\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(1),\n",
        "                           \n",
        "])\n",
        "\n",
        "#compile the model\n",
        "model.compile(loss=[\"mae\"],\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#fit the model\n",
        "#model.fit(X_train,y_train, epochs=100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrU-tQdAIqFu"
      },
      "source": [
        "We can visualize the model before we even run it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "XbxB0CFwIs4Q",
        "outputId": "5357c721-2269-42de-c13e-394d42fd4b58"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \"\"\"\n\u001b[1;32m   2375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2377\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UnsDpOtI7XC"
      },
      "source": [
        "the model hasn't been built yet, we can define the input_shape in the first layer itself to automatically built the data, or we can use the model.build(shape) to build the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZbkvackJG5l"
      },
      "source": [
        "#lets build a model that builds automatically\n",
        "tf.random.set_seed(42)\n",
        "model_1=tf.keras.Sequential([\n",
        "                      tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
        "                      tf.keras.layers.Dense(1, name=\"output_layer\")\n",
        "  #the input shape is 1 because X[0] and y[0] are scalar values, since\n",
        "  #we are passing only one number we give it a shape 1     \n",
        "], name=\"model_1\")\n",
        "model_1.compile(loss=\"mae\",\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk6xaFg2J2Ud",
        "outputId": "7e47ba87-779f-42ea-c171-9276741e3a81"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzweKnf3KH3n"
      },
      "source": [
        "#Dense means fully connected aka all neurons of one layer are connected to the next one\n",
        "\n",
        "Here we have output shape of 1 with 2 parameters X&y\n",
        "\n",
        "trainable parameters- are parametres (patterns) the model can update as it trains\n",
        "\n",
        "sometime when we import an already trained model we may freeze them, in which case they'll appear in the non- trainable params they raen't updated during training nad are used in transfer learning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJOxkNPlK8ar"
      },
      "source": [
        "#weights and biases\n",
        "mit introduction to deep learning \n",
        "\n",
        "#by chaning your hidden layer you will change the number of params affecting your model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALoL02YYKXmb",
        "outputId": "c1b56e1e-cce6-4725-9f6e-200239b56b47"
      },
      "source": [
        "model_1.fit(X_train,y_train,epochs=100,verbose=0)\n",
        "#verbose is simply for progress track 0 for silent 1 for progress bar 2 for one line per epoch\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c50d82910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OTcyAc2MJ6L",
        "outputId": "61815725-0742-4171-b6ad-d36f4c93f318"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "gL-ZQCy9MVXV",
        "outputId": "bcd1636c-3695-4b78-c447-7163dd65bdb3"
      },
      "source": [
        "#here we get to see again that 2 trainable parameters \n",
        "#per dense hidden unit\n",
        "#we can also visualize our model through\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model=model, show_shapes=True)#converts a keras model to dot format and save to a file\n",
        "#we can use to_file='file.png' to save it \n",
        "#we can use show_shapes=true (false by default)\n",
        "#also show_layers\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMPuuIxmNTVl"
      },
      "source": [
        "#now we have to visualize again at our model's prediction\n",
        "\n",
        "we visualize predicitons as a plot against the ground truth labels\n",
        "\n",
        "often we'll see it as y_test vs y_true\n",
        "or y_pred (ground truth versus your model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cwPUbKoPqZ1",
        "outputId": "f9d6faca-8c99-4892-d55c-97aaef8c568c"
      },
      "source": [
        "y_pred=model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c50c72830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50.16736],\n",
              "       [53.51185],\n",
              "       [56.85634],\n",
              "       [60.20083],\n",
              "       [63.54532],\n",
              "       [66.88981],\n",
              "       [70.2343 ],\n",
              "       [73.57879],\n",
              "       [76.92328],\n",
              "       [80.26778]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehh0WFkrP0kG",
        "outputId": "9590054a-68db-41f9-b88a-944e3cba1915"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEYGXwUsP1jq"
      },
      "source": [
        "#here we have the values that predict our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LooYKLFdP7Wn"
      },
      "source": [
        "#lets create the plotting function\n",
        "#if you feel like you're going to use some functionality in the future\n",
        "#it's better to make it into a funciton\n",
        "\n",
        "def plot_prediction(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     prediction=y_pred):\n",
        "  \"\"\"\n",
        "  Plot training data,test data, predicitions to the ground truth labels\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "  #plt training data\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",label=\"training data\")\n",
        "  #plt test data\n",
        "  plt.scatter(test_data,test_labels,c=\"g\",label=\"test data\")\n",
        "  #plot predicitons in red\n",
        "  plt.scatter(test_data, prediction,c=\"r\",label=\"predicitons\")\n",
        "  #show the legend\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "R-KbIeTaRrx4",
        "outputId": "a24f4055-4233-4817-f655-2f09903329d7"
      },
      "source": [
        "plot_prediction(train_data=X_train,\n",
        "                train_labels=y_train,\n",
        "                test_data=X_test,\n",
        "                test_labels=y_test,\n",
        "                prediction=y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17HYRD6zRt2q"
      },
      "source": [
        "###Evaluating the model's prediciton with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you're wokring on there iwll be diffrenet metrics to evaluate your model's performance \n",
        "\n",
        "Since we're working on regression, two of the main metrics:\n",
        "\n",
        "**MAE(mean absolute error)-ie on average how wrong is each of my models predictions\n",
        "\n",
        "**MSE-Mean square error where we square errors. use when larger errors are more significant than smaller errors\n",
        "\n",
        "**Huber- Combination of MSE and MAE less sensitive to outliers than MSE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WofOyQR4Sss1",
        "outputId": "73793175-d383-44bd-f002-6b032d10119a"
      },
      "source": [
        "#evaluate the model for test data\n",
        "\n",
        "model.evaluate(X_test,y_test)\n",
        "#retunrs the loss value and metrics value for model in the test mode\n",
        "#remember since we are setting loss=mae the loss value and the mae metric\n",
        "#value will be the same\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 191ms/step - loss: 22.7824 - mae: 22.7824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22.78243637084961, 22.78243637084961]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx2f8udTUMxH",
        "outputId": "aea448b7-c358-4a52-e4f7-73261d221bee"
      },
      "source": [
        "#calculate the MAE\n",
        "my_mae=tf.keras.losses.mae(y_true=y_test,y_pred=y_pred)\n",
        "my_mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([37.83264 , 34.48815 , 31.143661, 27.79917 , 24.454681, 21.110191,\n",
              "       17.812561, 15.136969, 13.046033, 11.492889], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXK1S1ybVw7d"
      },
      "source": [
        "#here we are getting these said values because when converted to tensors you can see that y_pred and y_true don't have the same shape, and thus require reshaping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOuxOf0-V7C6",
        "outputId": "1fdb67c7-76fb-4025-85f9-e067d1dcc805"
      },
      "source": [
        "tf.constant(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[50.16736],\n",
              "       [53.51185],\n",
              "       [56.85634],\n",
              "       [60.20083],\n",
              "       [63.54532],\n",
              "       [66.88981],\n",
              "       [70.2343 ],\n",
              "       [73.57879],\n",
              "       [76.92328],\n",
              "       [80.26778]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F3PWv54WHuR",
        "outputId": "398e343a-ac86-417f-aab7-a3d0c9bef3e4"
      },
      "source": [
        "tf.constant(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYbSBzJvWLq8"
      },
      "source": [
        "y_test is of shape 10, while y_pred is of the shape 10,1 and thus they require reshaping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFJY-PdsWWP7",
        "outputId": "d50c38e1-373b-47de-91d9-b18885eeb916"
      },
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([50.16736, 53.51185, 56.85634, 60.20083, 63.54532, 66.88981,\n",
              "       70.2343 , 73.57879, 76.92328, 80.26778], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKz9IzooWhTG",
        "outputId": "00f5676d-2ec9-4fa2-f681-43a1327c9b9d"
      },
      "source": [
        "#calculate mae again\n",
        "my_mae=tf.keras.losses.mae(y_true=y_test,\n",
        "                           y_pred=tf.squeeze(y_pred))\n",
        "my_mae\n",
        "#here we get rthe same value from the evaluate function"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=22.782436>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSgDC7cAWuqm",
        "outputId": "a8e9a627-49f8-4164-cad8-28667ef40b27"
      },
      "source": [
        "#now lets calculate mse\n",
        "my_mse=tf.keras.losses.mse(y_true=y_test,\n",
        "                           y_pred=tf.squeeze(y_pred))\n",
        "my_mse\n",
        "#we got an mse of 13.070143, is larger because the errors are squared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=522.58435>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaJz21BiXIeV"
      },
      "source": [
        "#make some functions to reuse MAE and MSE for reuseability\n",
        "\n",
        "def mae(y_true, y_test):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "\n",
        "def mse(y_true, y_test):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred= tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S31i19njYK_5"
      },
      "source": [
        "###now we mkae improvements to our model again\n",
        "\n",
        "'''\n",
        "build-fit-evaulate-repeat\n",
        "'''\n",
        "1. get more data-more ex to train on for more oportunites to learn relationships between features  and laels\n",
        "2. make your model larger increasing the hidden unit in each layer\n",
        "3. train for longer- more time to find the pattersn i nyour data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09AvcoR9YeR7"
      },
      "source": [
        "#now build again with your instances. from the root\n",
        "1.aka 1 layer but more time 100 epochs\n",
        "2.2 layer for 100 epohc \n",
        "3. 2 layers for 500 epochs\n",
        "4.\n",
        "5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7rUH2WTZIOG",
        "outputId": "0e7f187e-6dfb-477c-828d-07e43c1d2199"
      },
      "source": [
        "#set random seed for reproducability\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#build the model\n",
        "model_1=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile them odel\n",
        "model_1.compile(loss=[\"mae\"],\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4124 - mae: 16.4124\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0829 - mae: 11.0829\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1242 - mae: 11.1242\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6945 - mae: 8.6945\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.8003 - mae: 9.8003\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5263 - mae: 9.5263\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4102 - mae: 8.4102\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1449 - mae: 9.1449\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.4932 - mae: 19.4932\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6061 - mae: 9.6061\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5992 - mae: 8.5992\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9324 - mae: 10.9324\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0574 - mae: 10.0574\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5679 - mae: 16.5679\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4537 - mae: 11.4537\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4056 - mae: 8.4056\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8417 - mae: 13.8417\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.6621 - mae: 11.6621\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.7623 - mae: 18.7623\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.5702 - mae: 15.5702\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9959 - mae: 10.9959\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.0023 - mae: 8.0023\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8593 - mae: 9.8593\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5796 - mae: 7.5796\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7226 - mae: 13.7226\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.1740 - mae: 17.1740\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.4233 - mae: 13.4233\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5473 - mae: 14.5473\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.8753 - mae: 9.8753\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.1187 - mae: 17.1187\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.5949 - mae: 24.5949\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6765 - mae: 7.6765\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2971 - mae: 9.2971\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1703 - mae: 14.1703\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8635 - mae: 10.8635\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.5689 - mae: 13.5689\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3448 - mae: 9.3448\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4804 - mae: 10.4804\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0178 - mae: 10.0178\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.8005 - mae: 10.8005\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7789 - mae: 7.7789\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2844 - mae: 10.2844\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.9628 - mae: 8.9628\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6243 - mae: 12.6243\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.1236 - mae: 14.1236\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2681 - mae: 8.2681\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0126 - mae: 9.0126\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6882 - mae: 10.6882\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7431 - mae: 7.7431\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3950 - mae: 9.3950\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9267 - mae: 8.9267\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9818 - mae: 16.9818\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8677 - mae: 14.8677\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.0413 - mae: 22.0413\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0640 - mae: 17.0640\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9520 - mae: 9.9520\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7522 - mae: 9.7522\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4378 - mae: 9.4378\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3373 - mae: 8.3373\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6425 - mae: 9.6425\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.7590 - mae: 11.7590\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7187 - mae: 11.7187\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2316 - mae: 7.2316\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7848 - mae: 17.7848\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6255 - mae: 12.6255\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.2840 - mae: 13.2840\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8471 - mae: 7.8471\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9708 - mae: 9.9708\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.4903 - mae: 12.4903\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5001 - mae: 8.5001\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9996 - mae: 9.9996\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.1797 - mae: 10.1797\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.0024 - mae: 13.0024\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3812 - mae: 10.3812\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7621 - mae: 9.7621\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5186 - mae: 11.5186\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.3070 - mae: 8.3070\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.4436 - mae: 9.4436\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3897 - mae: 20.3897\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.4751 - mae: 15.4751\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.0208 - mae: 9.0208\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3869 - mae: 13.3869\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9649 - mae: 7.9649\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5702 - mae: 7.5702\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9706 - mae: 9.9706\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.0533 - mae: 9.0533\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2670 - mae: 12.2670\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1986 - mae: 7.1986\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.0379 - mae: 13.0379\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1968 - mae: 7.1968\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5386 - mae: 7.5386\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0932 - mae: 7.0932\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.8860 - mae: 12.8860\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9620 - mae: 9.9620\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7739 - mae: 8.7739\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0861 - mae: 13.0861\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3848 - mae: 8.3848\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7828 - mae: 9.7828\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5252 - mae: 8.5252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c4ba9e390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "ltMfSqycZ5mX",
        "outputId": "b91654de-1609-454b-bd2e-9954849f97c3"
      },
      "source": [
        "#now we visualize the data for model_1\n",
        "y_pred_1=model_1.predict(X_test)\n",
        "plot_prediction(prediction=y_pred_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c50ca4200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGbCAYAAAAY8u5bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXhU9Z338c8XsHLFUmSRWiqS0IqCEA2QRZHSlQukVPFxa9ENu9pa2bbirtu9VSzdYt3NLq0PWO/60Hjp4u5Gq1a5q9a6FIVWW60bMAoFFNAEQRYCVsSmKJjv/cdM4iRMwkzmzMM55/26rlyZ+c1k5peZCX78nXM+x9xdAAAACE6fYk8AAAAgaghYAAAAASNgAQAABIyABQAAEDACFgAAQMD6FXsCqY466iivqKgo9jQAAAAOadWqVbvcfUi620oqYFVUVKihoaHY0wAAADgkM2vu7jY2EQIAAASMgAUAABAwAhYAAEDASmofrHT279+vrVu3at++fcWeCiT1799fw4YN02GHHVbsqQAAULJKPmBt3bpVAwYMUEVFhcys2NOJNXfX7t27tXXrVo0YMaLY0wEAoGSV/CbCffv2afDgwYSrEmBmGjx4MKuJAAAcQskHLEmEqxLCewEAwKGFImABAACECQHrEN555x3dcccdvfrZM888U++8806P9/nud7+r5cuX9+rxe7JkyRLNmzevx/usXLlSv/3tbwN/bgAA4o6AdQg9BawDBw70+LNPPvmkjjzyyB7vc8MNN2j69Om9nl8uCFgAAORH5AJWfb1UUSH16ZP4Xl+f2+PNnz9fmzdvVlVVla6++mqtXLlSU6ZM0TnnnKMTTzxRknTeeedpwoQJGjNmjOrq6jp+tqKiQrt27VJTU5NGjx6tyy+/XGPGjNGMGTP0pz/9SZJ06aWX6qc//WnH/RcuXKjx48ersrJSGzZskCS1tLTojDPO0JgxY/S1r31N5eXl2rVr10Fz/fd//3cdf/zxmjhxon7zm990jD/++OM65ZRTNG7cOE2fPl07duxQU1OT7rrrLi1evFhVVVV69tln094PAAD0gruXzNeECRO8q3Xr1h001p3/+i/3sjJ36aOvsrLEeG+98cYbPmbMmI7rK1as8LKyMn/99dc7xnbv3u3u7q2trT5mzBjftWuXu7uXl5d7S0uLv/HGG963b19/6aWX3N39wgsv9P/8z/90d/dLLrnEH3744Y7733bbbe7ufvvtt/tll13m7u5XXHGF/+u//qu7u//iF79wSd7S0tJpnm+99ZYfe+yxvnPnTn///ff9tNNO8yuuuMLd3d9++21va2tzd/e7777bv/Wtb7m7+8KFC/3GG2/seIzu7tdVNu8JAABRJanBu8k0Jd+DlY0FC6TW1s5jra2J8Zqa4J5n4sSJnXqgbrvtNi1dulSS9Oabb2rjxo0aPHhwp58ZMWKEqqqqJEkTJkxQU1NT2se+4IILOu7z6KOPSpKee+65jsefOXOmBg0adNDP/e53v9Ppp5+uIUMSJ/WePXu2XnvtNUmJLrHZs2dr+/bt+uCDD7rtsMr0fgAAoGeR2kS4ZUt24711xBFHdFxeuXKlli9frueff14vv/yyxo0bl7Yn6vDDD++43Ldv327332q/X0/3ydaVV16pefPmac2aNfrxj3/cbY9VpvcDAKBU1a+pV8WtFerzvT6quLVC9Wty3FeolyIVsIYPz248EwMGDNDevXu7vX3Pnj0aNGiQysrKtGHDBr3wwgu9f7JuTJ48WQ899JAkadmyZfrDH/5w0H1OOeUU/epXv9Lu3bu1f/9+Pfzww53meMwxx0iS7rvvvo7xrr9bd/cDACAM6tfUa+7jc9W8p1kuV/OeZs19fG5RQlakAlZtrVRW1nmsrCwx3luDBw/W5MmTNXbsWF199dUH3T5z5kwdOHBAo0eP1vz583Xqqaf2/sm6sXDhQi1btkxjx47Vww8/rE996lMaMGBAp/sMHTpU119/vSZNmqTJkydr9OjRHbddf/31uvDCCzVhwgQdddRRHeNnn322li5d2rGTe3f3AwAgDBY8vUCt+zvvK9S6v1ULnl5Q8LlYYh+t0lBdXe0NDQ2dxtavX98pLBxKfX1in6stWxIrV7W1we5/VQzvv/+++vbtq379+un555/XN77xDTU2NhZtPtm+JwAAFEKf7/WR6+BcYzK1LWwL/PnMbJW7V6e7LVI7uUuJMBX2QNXVli1b9OUvf1ltbW362Mc+prvvvrvYUwIAoOQMHzhczXua044XWuQCVhSNHDlSL730UrGnAQBASaudVqu5j8/ttJmw7LAy1U7LYV+hXorUPlgAACC+aiprVHd2ncoHlstkKh9Yrrqz61RTWfhNW6xgAQCAkle/pl4Lnl6gLXu2aPjA4aqdVps2ONVU1hQlUHVFwAIAACWtvX6hfdNfe/2CpJIIU+mwiRAAAJS0UqpfyFRWAcvM7jWznWa2NmXsz8zsl2a2Mfl9UHLczOw2M9tkZq+Y2figJ18I77zzju64445e//ytt96q1q7n70lj5cqVmjVrVo/3aWxs1JNPPtnruQAAEEZb9qQ/JUt346Ug2xWsJZJmdhmbL+lpdx8p6enkdUn6oqSRya+5ku7s/TSLp1ABKxMELABAHHVXs1CM+oVMZRWw3P3Xkt7uMnyupPbzqtwn6byU8f9InnD6BUlHmtnQXCabiaDPQTR//nxt3rxZVVVVHU3uN954o/78z/9cJ510khYuXChJ+uMf/6izzjpLJ598ssaOHasHH3xQt912m9566y1NnTpVU6dOPeixn3rqKY0aNUrjx4/vOLGzJL344ouaNGmSxo0bp9NOO02vvvqqPvjgA333u9/Vgw8+qKqqKj344INp7wcAQNTUTqtV2WGdT9VSrPqFTAWxk/vR7r49efl/JR2dvHyMpDdT7rc1ObY9ZUxmNleJFS4Nz+WkgcrPTnCLFi3S2rVrO5rTly1bpo0bN+rFF1+Uu+ucc87Rr3/9a7W0tOjTn/60fv7zn0tKnNdv4MCBuuWWW7RixYqDTj2zb98+XX755XrmmWd03HHHafbs2R23jRo1Ss8++6z69eun5cuX69vf/rYeeeQR3XDDDWpoaNCPfvQjSdK7776b9n4AAERJ+3/DMzmKsFQEehShu7uZZXXuHXevk1QnJU6Vk8vz97QTXFBvwrJly7Rs2TKNGzdOkvTee+9p48aNmjJliv7xH/9R1157rWbNmqUpU6b0+DgbNmzQiBEjNHLkSEnSnDlzVFdXJykRzi655BJt3LhRZqb9+/enfYxM7wcAQCnKtHpBKp36hUwFcRThjvZNf8nvO5Pj2yQdm3K/YcmxvCnETnDuruuuu06NjY1qbGzUpk2bdNlll+n444/X6tWrVVlZqe985zu64YYbev0c//RP/6SpU6dq7dq1evzxx7Vv376c7gcAQKlp3+rUvKdZLu/Y6pTrrj2lIoiA9ZikS5KXL5H0s5Txv0keTXiqpD0pmxLzIh87wQ0YMEB79+7tuP6FL3xB9957r9577z1J0rZt27Rz50699dZbKisr05w5c3T11Vdr9erVaX++3ahRo9TU1KTNmzdLkh544IGO2/bs2aNjjjlGkrRkyZJu59Ld/QAAKHVhrF7IRrY1DQ9Iel7SCWa21cwuk7RI0hlmtlHS9OR1SXpS0uuSNkm6W9I3A5t1N/KxE9zgwYM1efJkjR07VldffbVmzJihv/qrv9KkSZNUWVmpL33pS9q7d6/WrFmjiRMnqqqqSt/73vf0ne98R5I0d+5czZw586Cd3Pv376+6ujqdddZZGj9+vD75yU923HbNNdfouuuu07hx43TgwIGO8alTp2rdunUdO7l3dz8AAEpdGKsXsmHuOe32FKjq6mpvaGjoNLZ+/XqNHj0648fIZnsueifb9wQAgK4qbq1Q857mg8bLB5ar6aqmwk+oF8xslbtXp7stcqfKCdtOcAAAxFHttNpOR/5LpV+9kA1OlQMAAAquprJGdWfXqXxguUym8oHlqju7LjKLJJFbwQIAAMWV6e46Ud7qRMACAACByUfpdxixiRAAAAQm6vULmSJgAQCAwES9fiFTBKwCW7lypWbNmiVJeuyxx7Ro0aIe73/aaadJkpqamnT//ffnfX4AAOQiH6XfYUTACsiHH36Y9c+cc845mj9/fo/3+e1vfyuJgAUACId8lH6HUfQCVn29VFEh9emT+F6f+zmNmpqaNGrUKNXU1Gj06NH60pe+pNbWVlVUVOjaa6/V+PHj9fDDD2vZsmWaNGmSxo8frwsvvLDjdDpPPfWURo0apfHjx+vRRx/teNwlS5Zo3rx5kqQdO3bo/PPP18knn6yTTz65I1h9/OMflyTNnz9fzz77rKqqqrR48WLt27dPX/nKV1RZWalx48ZpxYoVHY95wQUXaObMmRo5cqSuueYaSYkAeOmll2rs2LGqrKzU4sWLc35dAADoKur1C5mK1lGE9fXS3LlSa3LnuubmxHVJqsntjX311Vd1zz33aPLkyfrqV7+qO+64Q1LiVDqrV6/Wrl27dMEFF2j58uU64ogj9P3vf1+33HKLrrnmGl1++eV65plndNxxx2n27NlpH//v/u7v9Bd/8RdaunSpPvzww45w1m7RokW66aab9MQTT0iSbr75ZpmZ1qxZow0bNmjGjBl67bXXJEmNjY166aWXdPjhh+uEE07QlVdeqZ07d2rbtm1au3atJOmdd97J6fUAAMQP9QuZi9YK1oIFH4Wrdq2tifEcHXvssZo8ebIkac6cOXruueckqSMwvfDCC1q3bp0mT56sqqoq3XfffWpubtaGDRs0YsQIjRw5UmamOXPmpH38Z555Rt/4xjckSX379tXAgQN7nM9zzz3X8VijRo1SeXl5R8CaNm2aBg4cqP79++vEE09Uc3OzPvOZz+j111/XlVdeqaeeekqf+MQncn5NAADx0V6/0LynWS7vqF+oX5P7lqIoilbA2tLNEQrdjWfBzNJeP+KIIyRJ7q4zzjhDjY2Namxs1Lp163TPPffk/Ly9cfjhh3dc7tu3rw4cOKBBgwbp5Zdf1umnn6677rpLX/va14oyNwBAOFG/kJ1oBazh3Ryh0N14FrZs2aLnn39eknT//ffrc5/7XKfbTz31VP3mN7/Rpk2bJEl//OMf9dprr2nUqFFqamrS5s2bJUkPPPBA2sefNm2a7rzzTkmJ/aX27NnT6fYBAwZo7969HdenTJmi+uT+Za+99pq2bNmiE044odv579q1S21tbfrLv/xL/cu//ItWr16dza8PAIg56heyE62AVVsrlXU+ckFlZYnxHJ1wwgm6/fbbNXr0aP3hD3/o2JzXbsiQIVqyZIkuvvhinXTSSZo0aZI2bNig/v37q66uTmeddZbGjx+vT37yk2kf/4c//KFWrFihyspKTZgwQevWret0+0knnaS+ffvq5JNP1uLFi/XNb35TbW1tqqys1OzZs7VkyZJOK1ddbdu2Taeffrqqqqo0Z84c/du//VvOrwkAID6oX8iOuXux59ChurraGxoaOo2tX79eo0ePzvxB6usT+1xt2ZJYuaqtzXkH96amJs2aNatjB/G4y/o9AQCEXtdT4EiJ+oU4HiHYzsxWuXt1utuidRShlAhTOQYqAADQWXuIyuQoQkQxYOVBRUUFq1cAgEjKtHpBon4hG6EIWO5+0FF8KI5S2qQMAMhN181+7dULkghSOSr5ndz79++v3bt38x/2EuDu2r17t/r371/sqQAAAhDJ6oU8nNGlN0p+BWvYsGHaunWrWlpaij0VKBF4hw0bVuxpAAACELnqhTye0SVbJR+wDjvsMI0YMaLY0wAAIHKGDxyu5j3NacdDqaczuhQ4YJX8JkIAAJAftdNqVXZY5/7IssPKVDst9/7IosjjGV2yRcACACCmaiprVHd2ncoHlstkKh9YHu5eqzye0SVbBCwAACKofk29Km6tUJ/v9VHFrRXdnpS5prJGTVc1qW1hm5quagpvuJLyekaXbBGwAACImPb6heY9zXJ5R/1CdyErFDI5OrCmRqqrk8rLJbPE97q6ohSQl/ypcgAAQHYqbq1Iu/N6+cByNV3VVPgJ5arr0YFSYmWqSOGpXU+nymEFCwCAiIlc/UJPRweWKAIWAAAR013NQmjrF0ro6MBMEbAAAIiYyNUvlNDRgZkiYAEAEDGRq18ooaMDM0XAAgAgJDKtXpBCUr+Q6XkDS+jowExxFCEAACHQXr2QenLmssPKwrsyVaJHBmajp6MICVgAAIRA5KoXKioSJ2Puqrxcamoq9Gx6hZoGAABCLnLVCyE8MjAbBCwAAEIgctULITwyMBs5BywzO8HMGlO+3jWzq8zsejPbljJ+ZhATBgAgjiJXvRDCIwOzkXPAcvdX3b3K3askTZDUKmlp8ubF7be5+5O5PhcAAHEVquqFkJ03MB8C3cndzGZIWujuk83seknvuftNmf48O7kDAOKofk29Fjy9QFv2bNHwgcNVO622NINTJiJwdGCmCrmT+0WSHki5Ps/MXjGze81sUDeTm2tmDWbW0NLSEvB0AAAobe31C817muVyNe9p1tzH5/bYcVXSQnjewHwIbAXLzD4m6S1JY9x9h5kdLWmXJJf0z5KGuvtXe3oMVrAAAHETufqFPn2kdNnCTGprK/x88qhQK1hflLTa3XdIkrvvcPcP3b1N0t2SJgb4XAAARELk6hcifnRgpoIMWBcrZfOgmQ1Nue18SWsDfC4AACIhcvULET86MFOBBCwzO0LSGZIeTRn+gZmtMbNXJE2V9A9BPBcAAFESqvoFjg7MGKfKAQCgyEJxFGGMjg7MFOciBACgCEIRnDIVgXMHBq2ngNWv0JMBACAO2usXWvcnVnza6xckhTNkRfzcgUHjXIQAAOTBgqcXdISrdq37W7Xg6ZD2QXF0YFYIWAAA5EHk6hc4OjArBCwAAPIgcvULHB2YFQIWAAB5EJr6hUyqF9rV1CR2aG9rS3wnXHWLgAUAQB7UVNao7uw6lQ8sl8lUPrBcdWfXldYO7u3VC83NidPbNDcnrvcUspARahoAAMhCfX3ivMVbtiT2766tDfFCDtULOaGmAQCAAHTt2mxf8JFCGrKoXsgbNhECAJChBQs6F5lLiesLQtq8QPVC/hCwAADIUOQWfKheyBsCFgAAGQrVgg8nZi4qAhYAABkKzYJPNkcHUr2QFwQsAAAyFJoFn8jtLBY+BCwAAJR532YoFnwit7NY+BCwAACxF7m+zVDtLBZNBCwAQOxFbotaaHYWiy4CFgAg9kKzRS2b7Zih2FksumhyBwDE3vDh6c8YU1Jb1LKtka+pIVAVEStYAIDYC8UWtchtx4w2AhYAIPZCsUUtNNsxIRGwAAARF5n6BY4MDBUCFgAgsiJVvxCK7ZhoR8ACAERWaHZb4ryBkWPuXuw5dKiurvaGhoZiTwMAEBF9+iRWrroyS2wKLAldjw6UEitThKeSZ2ar3L063W2sYAEAIisUuy2FZpkN2SBgAQAiKxS7LXF0YCQRsAAAkRWK3ZZCscyGbBGwAAChk2n1ghSC+oVQLLMhWwQsAECohKp6gaMDY4ujCAEAoVJRkf68geXliRWqksHRgZHHUYQAgMgIzT7hHB0YawQsAECohGaf8NAkQeQDAQsAECqh2Sc8NEkQ+UDAAgCESmj2CQ9NEkQ+BBawzKzJzNaYWaOZNSTH/szMfmlmG5PfBwX1fACA6Mm0fqHkqxekECVB5ENgRxGaWZOkanfflTL2A0lvu/siM5svaZC7X9vdY3AUIQDEFwfdIWyKeRThuZLuS16+T9J5eX4+AEBIcdAdoiTIgOWSlpnZKjObmxw72t23Jy//r6Sju/6Qmc01swYza2hpaQlwOgCAMOGgO0RJkAHrc+4+XtIXJV1hZp9PvdET2yIP2h7p7nXuXu3u1UOGDAlwOgCAMOGgO0RJYAHL3bclv++UtFTSREk7zGyoJCW/7wzq+QAA0cJBd4iSQAKWmR1hZgPaL0uaIWmtpMckXZK82yWSfhbE8wEAooeD7hAlQa1gHS3pOTN7WdKLkn7u7k9JWiTpDDPbKGl68joAIGYiVb8AZKBfEA/i7q9LOjnN+G5J04J4DgBAOHWtX2huTlyXCFCILprcAQB5Rf0C4oiABQDIK+oXEEcELABAXlG/gDgiYAEA8or6BcQRAQsAkFfULyCOAjmKEACAntTUEKgQL6xgAQB6JdNuKyCOWMECAGSNbiugZ6xgAQCyRrcV0DMCFgAga3RbAT0jYAEAska3FdAzAhYAIGt0WwE9I2ABALJGtxXQMwIWAKCTTOsXamqkpiaprS3xnXAFfISaBgBAB+oXgGCwggUA6ED9AhAMAhYAoAP1C0AwCFgAgA7ULwDBIGABADpQvwAEg4AFAOhA/QIQDAIWAMQE9QtA4VDTAAAxQP0CUFisYAFADFC/ABQWAQsAYoD6BaCwCFgAEAPULwCFRcACgBigfgEoLAIWAMQA9QtAYRGwACDEMq1ekKhfAAqJmgYACCmqF4DSxQoWAIQU1QtA6SJgAUBIUb0AlC4CFgCEFNULQOkiYAFASFG9AJQuAhYAhBTVC0DpImABQAnKtH6B6gWgNOUcsMzsWDNbYWbrzOz3Zvb3yfHrzWybmTUmv87MfboAEH3t9QvNzZL7R/ULPXVcASgt5u65PYDZUElD3X21mQ2QtErSeZK+LOk9d78p08eqrq72hoaGnOYDAGFXUZEIVV2VlydWqQCUBjNb5e7V6W7LuWjU3bdL2p68vNfM1ks6JtfHBYC4on4BCL9A98EyswpJ4yT9Ljk0z8xeMbN7zWxQkM8FAFFF/QIQfoEFLDP7uKRHJF3l7u9KulPSZyVVKbHCdXM3PzfXzBrMrKGlpSWo6QBAaFG/AIRfIAHLzA5TIlzVu/ujkuTuO9z9Q3dvk3S3pInpftbd69y92t2rhwwZEsR0ACDUqF8Awi+IowhN0j2S1rv7LSnjQ1Pudr6ktbk+FwCEHfULQDzkvJO7pMmS/lrSGjNrTI59W9LFZlYlySU1SfrbAJ4LAEKrvX6h/QTN7fULEgEKiJqcaxqCRE0DgCijfgGIlp5qGmhyB4ACoX4BiA8CFgAUCPULQHwQsACgQKhfAOKDgAUABUL9AhAfBCwAyFGm1QsS9QtAXARR0wAAsUX1AoB0WMECgBwsWPBRuGrX2poYBxBfBCwAyAHVCwDSIWABQA6oXgCQDgELAHJA9QKAdAhYAJADqhcApEPAAoBuZFq/QPUCgK6oaQCANKhfAJALVrAAIA3qFwDkgoAFAGlQvwAgFwQsAEiD+gUAuSBgAUAa1C8AyAUBCwDSoH4BQC4IWABih/oFAPlGTQOAWKF+AUAhsIIFIFaoXwBQCAQsALFC/QKAQiBgAYgV6hcAFAIBC0CsUL8AoBAIWABihfoFAIVAwAIQCZlWL0jULwDIP2oaAIQe1QsASg0rWABCj+oFAKWGgAUg9KheAFBqCFgAQo/qBQClhoAFIPSoXgBQaghYAEKP6gUApYaABaCkZVq/QPUCgFJCTQOAkkX9AoCwYgULQMmifgFAWBGwAJQs6hcAhFXeA5aZzTSzV81sk5nNz/fzAYgO6hcAhFVeA5aZ9ZV0u6QvSjpR0sVmdmI+nxNAdFC/ACCs8r2CNVHSJnd/3d0/kPQTSefm+TkBRAT1CwDCKt8B6xhJb6Zc35oc62Bmc82swcwaWlpa8jwdAKUg0+oFifoFAOFU9J3c3b3O3avdvXrIkCHFng6APGuvXmhultw/ql7oKWQBQNjkO2Btk3RsyvVhyTEAMUX1AoA4yHfA+h9JI81shJl9TNJFkh7L83MCKGFULwCIg7wGLHc/IGmepP+WtF7SQ+7++3w+J4DSRvUCgDjI+z5Y7v6kux/v7p91dw6uBmKO6gUAcVD0ndwBxAvVCwDigIAFIDCZ1i9QvQAg6voVewIAoqG9fqH9CMH2+gWJAAUgfljBAhAI6hcA4CMELACBoH4BAD5CwAIQCOoXAOAjBCwAgaB+AQA+QsACEAjqFwDgIwQsAIdE/QIAZIeaBgA9on4BALLHChaAHlG/AADZI2AB6BH1CwCQPQIWgB5RvwAA2SNgAegR9QsAkD0CFoAeUb8AANkjYAExlWn1gkT9AgBki5oGIIaoXgCA/GIFC4ghqhcAIL8IWEAMUb0AAPlFwAJiiOoFAMgvAhYQQ1QvAEB+EbCAGKJ6AQDyi4AFREym9QtULwBA/lDTAEQI9QsAUBpYwQIihPoFACgNBCwgQqhfAIDSQMACIoT6BQAoDQQsIEKoXwCA0kDAAiKE+gUAKA0ELCAkqF8AgPCgpgEIAeoXACBcWMECQoD6BQAIFwIWEALULwBAuBCwgBCgfgEAwoWABYQA9QsAEC45BSwzu9HMNpjZK2a21MyOTI5XmNmfzKwx+XVXMNMF4on6BQAIF3P33v+w2QxJz7j7ATP7viS5+7VmViHpCXcfm83jVVdXe0NDQ6/nAwAAUChmtsrdq9PdltMKlrsvc/cDyasvSBqWy+MBcZNptxUAIFyC3Afrq5J+kXJ9hJm9ZGa/MrMp3f2Qmc01swYza2hpaQlwOkBpa++2am6W3D/qtiJkAUD4HXIToZktl/SpNDctcPefJe+zQFK1pAvc3c3scEkfd/fdZjZB0v+TNMbd3+3pudhEiDipqEiEqq7KyxMN7ACA0tbTJsJDNrm7+/RDPPilkmZJmubJtObu70t6P3l5lZltlnS8JNITkES3FQBEV65HEc6UdI2kc9y9NWV8iJn1TV7+jKSRkl7P5bmAqKHbCgCiK9d9sH4kaYCkX3apY/i8pFfMrFHSTyV93d3fzvG5gEih2woAoiunkz27+3HdjD8i6ZFcHhuIuvYOqwULEpsFhw9PhCu6rQAg/GhyB/Ig0/qFmprEDu1tbYnvhCsAiIacVrAAHKy9fqE1uVdie/2CRIACgLhgBQsI2IIFH4Wrdq2tiXEAQDwQsICAUb8AACBgAQGjfgEAQMACAkb9AgCAgAUErKZGqqtLnPLGLPG9ro4d3AEgTghYQBaoXwAAZIKaBiBD1C8AADLFChaQIeoXAACZIk2WqHQAAAwoSURBVGABGaJ+AQCQKQIWkCHqFwAAmSJgARmifgEAkCkCFpAh6hcAAJkiYCH2Mq1ekKhfAABkhpoGxBrVCwCAfGAFC7FG9QIAIB8IWIg1qhcAAPlAwEKsUb0AAMgHAhZijeoFAEA+ELAQa1QvAADygYCFyMq0foHqBQBA0KhpQCRRvwAAKCZWsBBJ1C8AAIqJgIVIon4BAFBMBCxEEvULAIBiImAhkqhfAAAUEwELkUT9AgCgmAhYCB3qFwAApY6aBoQK9QsAgDBgBQuhQv0CACAMCFgIFeoXAABhQMBCqFC/AAAIAwIWQoX6BQBAGBCwECrULwAAwiCngGVm15vZNjNrTH6dmXLbdWa2ycxeNbMv5D5VRFmm1QsS9QsAgNIXRE3DYne/KXXAzE6UdJGkMZI+LWm5mR3v7h8G8HyIGKoXAABRk69NhOdK+om7v+/ub0jaJGlinp4LIUf1AgAgaoIIWPPM7BUzu9fMBiXHjpH0Zsp9tibHDmJmc82swcwaWlpaApgOwobqBQBA1BwyYJnZcjNbm+brXEl3SvqspCpJ2yXdnO0E3L3O3avdvXrIkCFZ/wIIP6oXAABRc8h9sNx9eiYPZGZ3S3oieXWbpGNTbh6WHAMOUlvbeR8sieoFAEC45XoU4dCUq+dLWpu8/Jiki8zscDMbIWmkpBdzeS5EF9ULAICoyXUfrB+Y2Roze0XSVEn/IEnu/ntJD0laJ+kpSVdwBGE8ZVq/QPUCACBKcqppcPe/7uG2Wkls5Ikx6hcAAHFFkzvyhvoFAEBcEbCQN9QvAADiioCFvKF+AQAQVwQs5E1tbaJuIRX1CwCAOCBgIW+oXwAAxBUBC71C/QIAAN3LqaYB8UT9AgAAPWMFC1mjfgEAgJ4RsJA16hcAAOgZAQtZo34BAICeEbCQNeoXAADoGQELWaN+AQCAnhGw0CHT6gWJ+gUAAHpCTQMkUb0AAECQWMGCJKoXAAAIEgELkqheAAAgSAQsSKJ6AQCAIBGwIInqBQAAgkTAgiSqFwAACBIBKwYyrV+gegEAgGBQ0xBx1C8AAFB4rGBFHPULAAAUHgEr4qhfAACg8AhYEUf9AgAAhUfAijjqFwAAKDwCVsRRvwAAQOERsEIq0+oFifoFAAAKjZqGEKJ6AQCA0sYKVghRvQAAQGkjYIUQ1QsAAJQ2AlYIUb0AAEBpI2CFENULAACUNgJWCFG9AABAaSNglZhM6xeoXgAAoHRR01BCqF8AACAaclrBMrMHzawx+dVkZo3J8Qoz+1PKbXcFM91oo34BAIBoyGkFy91nt182s5sl7Um5ebO7V+Xy+HFD/QIAANEQyD5YZmaSvizpgSAeL66oXwAAIBqC2sl9iqQd7r4xZWyEmb1kZr8ysynd/aCZzTWzBjNraGlpCWg64UT9AgAA0XDIgGVmy81sbZqvc1PudrE6r15tlzTc3cdJ+pak+83sE+ke393r3L3a3auHDBmSy+8SetQvAAAQDYcMWO4+3d3Hpvn6mSSZWT9JF0h6MOVn3nf33cnLqyRtlnR8fn6FcKB+AQCA+AiipmG6pA3uvrV9wMyGSHrb3T80s89IGinp9QCeK5SoXwAAIF6C2AfrIh28c/vnJb2SrG34qaSvu/vbATxXKFG/AABAvOS8guXul6YZe0TSI7k+dlRQvwAAQLxwqpwCoH4BAIB4IWAVAPULAADECwGrAKhfAAAgXghYOci0ekGifgEAgDgJoqYhlqheAAAA3WEFq5eoXgAAAN0hYPUS1QsAAKA7BKxeonoBAAB0h4DVS1QvAACA7hCweonqBQAA0B0CVhqZ1i9QvQAAANKhpqEL6hcAAECuWMHqgvoFAACQKwJWF9QvAACAXBGwuqB+AQAA5IqA1QX1CwAAIFcErC6oXwAAALniKMI0amoIVAAAoPditYKVab8VAABALmKzgkW/FQAAKJTYrGDRbwUAAAolNgGLfisAAFAosQlY9FsBAIBCiU3Aot8KAAAUSmwCFv1WAACgUGJzFKFEvxUAACiM2KxgAQAAFAoBCwAAIGAELAAAgIARsAAAAAJGwAIAAAgYAQsAACBgBCwAAICAEbAAAAACRsACAAAIGAELAAAgYAQsAACAgBGwAAAAAmbuXuw5dDCzFknNBXiqoyTtKsDzlKq4//4Sr4HEayDxGsT995d4DSReg1x+/3J3H5LuhpIKWIViZg3uXl3seRRL3H9/iddA4jWQeA3i/vtLvAYSr0G+fn82EQIAAASMgAUAABCwuAasumJPoMji/vtLvAYSr4HEaxD331/iNZB4DfLy+8dyHywAAIB8iusKFgAAQN4QsAAAAAIW6YBlZhea2e/NrM3Mqrvcdp2ZbTKzV83sCynjM5Njm8xsfuFnnT9m9qCZNSa/msysMTleYWZ/SrntrmLPNV/M7Hoz25byu56Zclvaz0SUmNmNZrbBzF4xs6VmdmRyPDafASnaf+fdMbNjzWyFma1L/rv498nxbv8moib5796a5O/ZkBz7MzP7pZltTH4fVOx55ouZnZDyPjea2btmdlXUPwNmdq+Z7TSztSljad93S7gt+W/DK2Y2vtfPG+V9sMxstKQ2ST+W9H/cvf0P6kRJD0iaKOnTkpZLOj75Y69JOkPSVkn/I+lid19X4KnnnZndLGmPu99gZhWSnnD3scWdVf6Z2fWS3nP3m7qMp/1MuPuHBZ9kHpnZDEnPuPsBM/u+JLn7tTH7DPRVTP7OU5nZUElD3X21mQ2QtErSeZK+rDR/E1FkZk2Sqt19V8rYDyS97e6LkmF7kLtfW6w5Fkry72CbpFMkfUUR/gyY2eclvSfpP9r/jevufU+GyyslnanEa/NDdz+lN88b6RUsd1/v7q+muelcST9x9/fd/Q1Jm5T4D+tESZvc/XV3/0DST5L3jRQzMyX+UX2g2HMpId19JiLF3Ze5+4Hk1RckDSvmfIokFn/nXbn7dndfnby8V9J6SccUd1Yl4VxJ9yUv36dE6IyDaZI2u3shzp5SVO7+a0lvdxnu7n0/V4kg5u7+gqQjk/9zkrVIB6weHCPpzZTrW5Nj3Y1HzRRJO9x9Y8rYCDN7ycx+ZWZTijWxApmXXPq9N2VzQFze+1RflfSLlOtx+QzE8b3uJLliOU7S75JD6f4mosglLTOzVWY2Nzl2tLtvT17+X0lHF2dqBXeROv9Pdlw+A+26e98D+/ch9AHLzJab2do0X5H/P9J0Mnw9LlbnP6ztkoa7+zhJ35J0v5l9opDzDtIhXoM7JX1WUpUSv/fNRZ1sHmTyGTCzBZIOSKpPDkXqM4DumdnHJT0i6Sp3f1cx+JtI8Tl3Hy/pi5KuSG466uCJfWaiu99Mkpl9TNI5kh5ODsXpM3CQfL3v/YJ+wEJz9+m9+LFtko5NuT4sOaYexkPhUK+HmfWTdIGkCSk/876k95OXV5nZZiX2SWvI41TzJtPPhJndLemJ5NWePhOhksFn4FJJsyRNS/7DErnPwCFE5r3OlpkdpkS4qnf3RyXJ3Xek3J76NxE57r4t+X2nmS1VYnPxDjMb6u7bk5uCdhZ1koXxRUmr29/7OH0GUnT3vgf270PoV7B66TFJF5nZ4WY2QtJISS8qsbPrSDMbkUz4FyXvGyXTJW1w963tA2Y2JLnDo8zsM0q8Hq8XaX551WVb+vmS2o8q6e4zESlmNlPSNZLOcffWlPHYfAYUj7/zgyT3vbxH0np3vyVlvLu/iUgxsyOSO/fLzI6QNEOJ3/UxSZck73aJpJ8VZ4YF1WkrRlw+A110974/JulvkkcTnqrEwWDb0z3AoYR+BasnZna+pP8raYikn5tZo7t/wd1/b2YPSVqnxGaSK9qPFjOzeZL+W1JfSfe6+++LNP186brdXZI+L+kGM9uvxFGXX3f3rjsERsUPzKxKieXgJkl/K0k9fSYi5keSDpf0y8R/b/WCu39dMfoMJI+gjPrfeTqTJf21pDWWrGiR9G1JF6f7m4igoyUtTX7u+0m6392fMrP/kfSQmV0mqVmJA4AiKxkuz1Dn9zntv4tRYWYPSDpd0lFmtlXSQkmLlP59f1KJIwg3SWpV4gjL3j1vlGsaAAAAiiGumwgBAADyhoAFAAAQMAIWAABAwAhYAAAAASNgAQAABIyABQAAEDACFgAAQMD+P0SPcJa2PC2AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKD6b9yCabCz",
        "outputId": "79227e6c-05c7-4c9e-c1f0-77f07c305201"
      },
      "source": [
        "#calculate model_1 evaluate\n",
        "mae_1=mae(y_test, y_pred_1)\n",
        "mse_1=mse(y_test, y_pred_1)\n",
        "mae_1,mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=22.782436>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=522.58435>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKOpMmn_a5x0"
      },
      "source": [
        "#Build model_2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-mfu2OZchOw",
        "outputId": "ceca427a-deaa-466a-8d8a-9a39190eb1c8"
      },
      "source": [
        "#set the seed\n",
        "tf.random.set_seed(42)\n",
        "#build the model\n",
        "model_2=tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(10),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                           \n",
        "])\n",
        "#compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mse,\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "                metrics=[\"mse\"])\n",
        "#fit the model\n",
        "model_2.fit(X_train,y_train,epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 842.4100 - mse: 842.4100\n",
            "Epoch 2/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 506.6599 - mse: 506.6599\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 258.9877 - mse: 258.9877\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 119.2437 - mse: 119.2437\n",
            "Epoch 5/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 78.5779 - mse: 78.5779\n",
            "Epoch 6/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 108.8009 - mse: 108.8009\n",
            "Epoch 7/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 155.9883 - mse: 155.9883\n",
            "Epoch 8/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 173.8792 - mse: 173.8792\n",
            "Epoch 9/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 169.7999 - mse: 169.7999\n",
            "Epoch 10/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 133.9067 - mse: 133.9067\n",
            "Epoch 11/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 95.8457 - mse: 95.8457\n",
            "Epoch 12/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 78.6097 - mse: 78.6097\n",
            "Epoch 13/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 73.5657 - mse: 73.5657\n",
            "Epoch 14/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 76.7030 - mse: 76.7030\n",
            "Epoch 15/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 81.7716 - mse: 81.7716\n",
            "Epoch 16/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 86.9803 - mse: 86.9803\n",
            "Epoch 17/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 76.5426 - mse: 76.5426\n",
            "Epoch 18/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 81.7375 - mse: 81.7375\n",
            "Epoch 19/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 72.6653 - mse: 72.6653\n",
            "Epoch 20/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 64.6713 - mse: 64.6713\n",
            "Epoch 21/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 62.6615 - mse: 62.6615\n",
            "Epoch 22/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 60.4332 - mse: 60.4332\n",
            "Epoch 23/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 63.2835 - mse: 63.2835\n",
            "Epoch 24/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 62.0377 - mse: 62.0377\n",
            "Epoch 25/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 61.3883 - mse: 61.3883\n",
            "Epoch 26/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 58.4126 - mse: 58.4126\n",
            "Epoch 27/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 56.7794 - mse: 56.7794\n",
            "Epoch 28/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 54.8487 - mse: 54.8487\n",
            "Epoch 29/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 56.7084 - mse: 56.7084\n",
            "Epoch 30/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 56.6779 - mse: 56.6779\n",
            "Epoch 31/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 54.0551 - mse: 54.0551\n",
            "Epoch 32/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 54.6255 - mse: 54.6255\n",
            "Epoch 33/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 51.9445 - mse: 51.9445\n",
            "Epoch 34/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 49.2630 - mse: 49.2630\n",
            "Epoch 35/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 50.5276 - mse: 50.5276\n",
            "Epoch 36/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 46.0017 - mse: 46.0017\n",
            "Epoch 37/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 45.2080 - mse: 45.2080\n",
            "Epoch 38/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 45.5128 - mse: 45.5128\n",
            "Epoch 39/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 44.5017 - mse: 44.5017\n",
            "Epoch 40/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 43.1152 - mse: 43.1152\n",
            "Epoch 41/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.3475 - mse: 40.3475\n",
            "Epoch 42/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 40.8720 - mse: 40.8720\n",
            "Epoch 43/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 41.1080 - mse: 41.1080\n",
            "Epoch 44/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 39.4688 - mse: 39.4688\n",
            "Epoch 45/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 37.9397 - mse: 37.9397\n",
            "Epoch 46/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.2071 - mse: 37.2071\n",
            "Epoch 47/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 36.2001 - mse: 36.2001\n",
            "Epoch 48/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.6165 - mse: 34.6165\n",
            "Epoch 49/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 35.2308 - mse: 35.2308\n",
            "Epoch 50/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.5626 - mse: 32.5626\n",
            "Epoch 51/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.8854 - mse: 32.8854\n",
            "Epoch 52/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.8615 - mse: 32.8615\n",
            "Epoch 53/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.3453 - mse: 32.3453\n",
            "Epoch 54/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 31.0122 - mse: 31.0122\n",
            "Epoch 55/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.5729 - mse: 29.5729\n",
            "Epoch 56/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.3633 - mse: 28.3633\n",
            "Epoch 57/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 27.4744 - mse: 27.4744\n",
            "Epoch 58/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.9009 - mse: 27.9009\n",
            "Epoch 59/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.9824 - mse: 25.9824\n",
            "Epoch 60/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.7853 - mse: 25.7853\n",
            "Epoch 61/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.7916 - mse: 24.7916\n",
            "Epoch 62/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.1435 - mse: 24.1435\n",
            "Epoch 63/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.9601 - mse: 23.9601\n",
            "Epoch 64/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.5739 - mse: 22.5739\n",
            "Epoch 65/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.4823 - mse: 22.4823\n",
            "Epoch 66/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.2950 - mse: 21.2950\n",
            "Epoch 67/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1057 - mse: 21.1057\n",
            "Epoch 68/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.7925 - mse: 20.7925\n",
            "Epoch 69/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.3868 - mse: 19.3868\n",
            "Epoch 70/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.2578 - mse: 18.2578\n",
            "Epoch 71/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.6285 - mse: 17.6285\n",
            "Epoch 72/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.3888 - mse: 17.3888\n",
            "Epoch 73/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.8704 - mse: 16.8704\n",
            "Epoch 74/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4236 - mse: 16.4236\n",
            "Epoch 75/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9050 - mse: 15.9050\n",
            "Epoch 76/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.1695 - mse: 15.1695\n",
            "Epoch 77/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5385 - mse: 14.5385\n",
            "Epoch 78/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.4275 - mse: 14.4275\n",
            "Epoch 79/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6614 - mse: 13.6614\n",
            "Epoch 80/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8410 - mse: 12.8410\n",
            "Epoch 81/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.3372 - mse: 12.3372\n",
            "Epoch 82/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.7755 - mse: 11.7755\n",
            "Epoch 83/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4117 - mse: 11.4117\n",
            "Epoch 84/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8305 - mse: 10.8305\n",
            "Epoch 85/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5741 - mse: 10.5741\n",
            "Epoch 86/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3227 - mse: 10.3227\n",
            "Epoch 87/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6111 - mse: 9.6111\n",
            "Epoch 88/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1261 - mse: 9.1261\n",
            "Epoch 89/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8256 - mse: 8.8256\n",
            "Epoch 90/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3622 - mse: 8.3622\n",
            "Epoch 91/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8466 - mse: 7.8466\n",
            "Epoch 92/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5705 - mse: 7.5705\n",
            "Epoch 93/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3461 - mse: 7.3461\n",
            "Epoch 94/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.9460 - mse: 6.9460\n",
            "Epoch 95/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5712 - mse: 6.5712\n",
            "Epoch 96/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1309 - mse: 6.1309\n",
            "Epoch 97/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8345 - mse: 5.8345\n",
            "Epoch 98/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5428 - mse: 5.5428\n",
            "Epoch 99/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.3617 - mse: 5.3617\n",
            "Epoch 100/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.0356 - mse: 5.0356\n",
            "Epoch 101/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.7897 - mse: 4.7897\n",
            "Epoch 102/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3917 - mse: 4.3917\n",
            "Epoch 103/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3746 - mse: 4.3746\n",
            "Epoch 104/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0299 - mse: 4.0299\n",
            "Epoch 105/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8223 - mse: 3.8223\n",
            "Epoch 106/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.6503 - mse: 3.6503\n",
            "Epoch 107/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.4497 - mse: 3.4497\n",
            "Epoch 108/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.2876 - mse: 3.2876\n",
            "Epoch 109/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.0132 - mse: 3.0132\n",
            "Epoch 110/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8292 - mse: 2.8292\n",
            "Epoch 111/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5631 - mse: 2.5631\n",
            "Epoch 112/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5821 - mse: 2.5821\n",
            "Epoch 113/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.4517 - mse: 2.4517\n",
            "Epoch 114/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.2265 - mse: 2.2265\n",
            "Epoch 115/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0657 - mse: 2.0657\n",
            "Epoch 116/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9169 - mse: 1.9169\n",
            "Epoch 117/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.8044 - mse: 1.8044\n",
            "Epoch 118/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6570 - mse: 1.6570\n",
            "Epoch 119/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6731 - mse: 1.6731\n",
            "Epoch 120/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4778 - mse: 1.4778\n",
            "Epoch 121/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.4264 - mse: 1.4264\n",
            "Epoch 122/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3209 - mse: 1.3209\n",
            "Epoch 123/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2571 - mse: 1.2571\n",
            "Epoch 124/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1463 - mse: 1.1463\n",
            "Epoch 125/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0149 - mse: 1.0149\n",
            "Epoch 126/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9619 - mse: 0.9619\n",
            "Epoch 127/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9612 - mse: 0.9612\n",
            "Epoch 128/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8633 - mse: 0.8633\n",
            "Epoch 129/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7919 - mse: 0.7919\n",
            "Epoch 130/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7356 - mse: 0.7356\n",
            "Epoch 131/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7430 - mse: 0.7430\n",
            "Epoch 132/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6810 - mse: 0.6810\n",
            "Epoch 133/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6245 - mse: 0.6245\n",
            "Epoch 134/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5212 - mse: 0.5212\n",
            "Epoch 135/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.4811 - mse: 0.4811\n",
            "Epoch 136/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4645 - mse: 0.4645\n",
            "Epoch 137/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4244 - mse: 0.4244\n",
            "Epoch 138/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.3871 - mse: 0.3871\n",
            "Epoch 139/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.3601 - mse: 0.3601\n",
            "Epoch 140/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3264 - mse: 0.3264\n",
            "Epoch 141/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3068 - mse: 0.3068\n",
            "Epoch 142/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2759 - mse: 0.2759\n",
            "Epoch 143/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2476 - mse: 0.2476\n",
            "Epoch 144/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2481 - mse: 0.2481\n",
            "Epoch 145/300\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.2108 - mse: 0.2108\n",
            "Epoch 146/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1803 - mse: 0.1803\n",
            "Epoch 147/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1807 - mse: 0.1807\n",
            "Epoch 148/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1590 - mse: 0.1590\n",
            "Epoch 149/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1413 - mse: 0.1413\n",
            "Epoch 150/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1343 - mse: 0.1343\n",
            "Epoch 151/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1176 - mse: 0.1176\n",
            "Epoch 152/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1101 - mse: 0.1101\n",
            "Epoch 153/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0950 - mse: 0.0950\n",
            "Epoch 154/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0878 - mse: 0.0878\n",
            "Epoch 155/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0816 - mse: 0.0816\n",
            "Epoch 156/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 157/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0656 - mse: 0.0656\n",
            "Epoch 158/300\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0585 - mse: 0.0585\n",
            "Epoch 159/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0582 - mse: 0.0582\n",
            "Epoch 160/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 161/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0431 - mse: 0.0431\n",
            "Epoch 162/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0403 - mse: 0.0403\n",
            "Epoch 163/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0361 - mse: 0.0361\n",
            "Epoch 164/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0313 - mse: 0.0313\n",
            "Epoch 165/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0278 - mse: 0.0278\n",
            "Epoch 166/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0262 - mse: 0.0262\n",
            "Epoch 167/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0225 - mse: 0.0225\n",
            "Epoch 168/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0204 - mse: 0.0204\n",
            "Epoch 169/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0183 - mse: 0.0183\n",
            "Epoch 170/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0165 - mse: 0.0165\n",
            "Epoch 171/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0144 - mse: 0.0144\n",
            "Epoch 172/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0134 - mse: 0.0134\n",
            "Epoch 173/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0116\n",
            "Epoch 174/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106\n",
            "Epoch 175/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0095 - mse: 0.0095\n",
            "Epoch 176/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0083\n",
            "Epoch 177/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0074\n",
            "Epoch 178/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0065 - mse: 0.0065\n",
            "Epoch 179/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056\n",
            "Epoch 180/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0053 - mse: 0.0053\n",
            "Epoch 181/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0048 - mse: 0.0048\n",
            "Epoch 182/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 183/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 184/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 185/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 186/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 187/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0023 - mse: 0.0023\n",
            "Epoch 188/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0019 - mse: 0.0019\n",
            "Epoch 189/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0018 - mse: 0.0018\n",
            "Epoch 190/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015 - mse: 0.0015\n",
            "Epoch 191/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 192/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0012 - mse: 0.0012\n",
            "Epoch 193/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0010 - mse: 0.0010    \n",
            "Epoch 194/300\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.0119e-04 - mse: 9.0119e-04\n",
            "Epoch 195/300\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 7.9692e-04 - mse: 7.9692e-04\n",
            "Epoch 196/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6458e-04 - mse: 6.6458e-04\n",
            "Epoch 197/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1247e-04 - mse: 6.1247e-04\n",
            "Epoch 198/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.6252e-04 - mse: 5.6252e-04\n",
            "Epoch 199/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.6459e-04 - mse: 4.6459e-04\n",
            "Epoch 200/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.0508e-04 - mse: 4.0508e-04\n",
            "Epoch 201/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.9178e-04 - mse: 3.9178e-04\n",
            "Epoch 202/300\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.2223e-04 - mse: 3.2223e-04\n",
            "Epoch 203/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.6193e-04 - mse: 2.6193e-04\n",
            "Epoch 204/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.3396e-04 - mse: 2.3396e-04\n",
            "Epoch 205/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1993e-04 - mse: 2.1993e-04\n",
            "Epoch 206/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9135e-04 - mse: 1.9135e-04\n",
            "Epoch 207/300\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5568e-04 - mse: 1.5568e-04\n",
            "Epoch 208/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3246e-04 - mse: 1.3246e-04\n",
            "Epoch 209/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.3051e-04 - mse: 1.3051e-04\n",
            "Epoch 210/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0226e-04 - mse: 1.0226e-04\n",
            "Epoch 211/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3394e-05 - mse: 8.3394e-05\n",
            "Epoch 212/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7259e-05 - mse: 7.7259e-05\n",
            "Epoch 213/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9058e-05 - mse: 6.9058e-05\n",
            "Epoch 214/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.6314e-05 - mse: 5.6314e-05\n",
            "Epoch 215/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8881e-05 - mse: 4.8881e-05\n",
            "Epoch 216/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.7076e-05 - mse: 4.7076e-05\n",
            "Epoch 217/300\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 3.6616e-05 - mse: 3.6616e-05\n",
            "Epoch 218/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.0207e-05 - mse: 3.0207e-05\n",
            "Epoch 219/300\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.8761e-05 - mse: 2.8761e-05\n",
            "Epoch 220/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.6217e-05 - mse: 2.6217e-05\n",
            "Epoch 221/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9906e-05 - mse: 1.9906e-05\n",
            "Epoch 222/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.8972e-05 - mse: 1.8972e-05\n",
            "Epoch 223/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7285e-05 - mse: 1.7285e-05\n",
            "Epoch 224/300\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2694e-05 - mse: 1.2694e-05\n",
            "Epoch 225/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1647e-05 - mse: 1.1647e-05\n",
            "Epoch 226/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2281e-05 - mse: 1.2281e-05\n",
            "Epoch 227/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.8954e-06 - mse: 8.8954e-06\n",
            "Epoch 228/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.4074e-06 - mse: 6.4074e-06\n",
            "Epoch 229/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.6527e-06 - mse: 6.6527e-06\n",
            "Epoch 230/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.6879e-06 - mse: 5.6879e-06\n",
            "Epoch 231/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8578e-06 - mse: 3.8578e-06\n",
            "Epoch 232/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.4150e-06 - mse: 3.4150e-06\n",
            "Epoch 233/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.9753e-06 - mse: 2.9753e-06\n",
            "Epoch 234/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.3596e-06 - mse: 2.3596e-06\n",
            "Epoch 235/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.0054e-06 - mse: 2.0054e-06\n",
            "Epoch 236/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.9636e-06 - mse: 1.9636e-06\n",
            "Epoch 237/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.4039e-06 - mse: 1.4039e-06\n",
            "Epoch 238/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1943e-06 - mse: 1.1943e-06\n",
            "Epoch 239/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1052e-06 - mse: 1.1052e-06\n",
            "Epoch 240/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1300e-07 - mse: 9.1300e-07\n",
            "Epoch 241/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8867e-07 - mse: 6.8867e-07\n",
            "Epoch 242/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8817e-07 - mse: 5.8817e-07\n",
            "Epoch 243/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.7631e-07 - mse: 4.7631e-07\n",
            "Epoch 244/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.0359e-07 - mse: 4.0359e-07\n",
            "Epoch 245/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.2771e-07 - mse: 3.2771e-07\n",
            "Epoch 246/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8596e-07 - mse: 2.8596e-07\n",
            "Epoch 247/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2993e-07 - mse: 2.2993e-07\n",
            "Epoch 248/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.8650e-07 - mse: 1.8650e-07\n",
            "Epoch 249/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7018e-07 - mse: 1.7018e-07\n",
            "Epoch 250/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4504e-07 - mse: 1.4504e-07\n",
            "Epoch 251/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.1226e-07 - mse: 1.1226e-07\n",
            "Epoch 252/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6737e-08 - mse: 8.6737e-08\n",
            "Epoch 253/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2192e-08 - mse: 7.2192e-08\n",
            "Epoch 254/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.1594e-08 - mse: 6.1594e-08\n",
            "Epoch 255/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.8090e-08 - mse: 4.8090e-08\n",
            "Epoch 256/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9689e-08 - mse: 3.9689e-08\n",
            "Epoch 257/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2552e-08 - mse: 3.2552e-08\n",
            "Epoch 258/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.7946e-08 - mse: 2.7946e-08\n",
            "Epoch 259/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.3887e-08 - mse: 2.3887e-08\n",
            "Epoch 260/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8384e-08 - mse: 1.8384e-08\n",
            "Epoch 261/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4755e-08 - mse: 1.4755e-08\n",
            "Epoch 262/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3615e-08 - mse: 1.3615e-08\n",
            "Epoch 263/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8250e-09 - mse: 9.8250e-09\n",
            "Epoch 264/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6485e-09 - mse: 8.6485e-09\n",
            "Epoch 265/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6112e-09 - mse: 8.6112e-09\n",
            "Epoch 266/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.4043e-09 - mse: 6.4043e-09\n",
            "Epoch 267/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9560e-09 - mse: 3.9560e-09\n",
            "Epoch 268/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.7241e-09 - mse: 3.7241e-09\n",
            "Epoch 269/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.1730e-09 - mse: 3.1730e-09\n",
            "Epoch 270/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8582e-09 - mse: 1.8582e-09\n",
            "Epoch 271/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8304e-09 - mse: 1.8304e-09\n",
            "Epoch 272/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.6939e-09 - mse: 1.6939e-09\n",
            "Epoch 273/300\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.0601e-09 - mse: 1.0601e-09\n",
            "Epoch 274/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2288e-10 - mse: 9.2288e-10\n",
            "Epoch 275/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4655e-10 - mse: 8.4655e-10\n",
            "Epoch 276/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.8173e-10 - mse: 6.8173e-10\n",
            "Epoch 277/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8318e-10 - mse: 3.8318e-10\n",
            "Epoch 278/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0980e-10 - mse: 5.0980e-10\n",
            "Epoch 279/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.7811e-10 - mse: 4.7811e-10\n",
            "Epoch 280/300\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.8540e-10 - mse: 1.8540e-10\n",
            "Epoch 281/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2450e-10 - mse: 2.2450e-10\n",
            "Epoch 282/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.2898e-10 - mse: 2.2898e-10\n",
            "Epoch 283/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6208e-10 - mse: 1.6208e-10\n",
            "Epoch 284/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.6123e-11 - mse: 6.6123e-11\n",
            "Epoch 285/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1048e-11 - mse: 5.1048e-11\n",
            "Epoch 286/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.9453e-11 - mse: 5.9453e-11\n",
            "Epoch 287/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.1023e-11 - mse: 6.1023e-11\n",
            "Epoch 288/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1557e-11 - mse: 4.1557e-11\n",
            "Epoch 289/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6266e-11 - mse: 4.6266e-11\n",
            "Epoch 290/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.3796e-11 - mse: 4.3796e-11\n",
            "Epoch 291/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.5682e-11 - mse: 5.5682e-11\n",
            "Epoch 292/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8814e-11 - mse: 5.8814e-11\n",
            "Epoch 293/300\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7129e-11 - mse: 4.7129e-11\n",
            "Epoch 294/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.1141e-11 - mse: 4.1141e-11\n",
            "Epoch 295/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.0631e-11 - mse: 4.0631e-11\n",
            "Epoch 296/300\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.7500e-11 - mse: 3.7500e-11\n",
            "Epoch 297/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.8559e-11 - mse: 3.8559e-11\n",
            "Epoch 298/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.9034e-11 - mse: 3.9034e-11\n",
            "Epoch 299/300\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.9310e-11 - mse: 3.9310e-11\n",
            "Epoch 300/300\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.2505e-11 - mse: 4.2505e-11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3c50b01e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "tC7UpFXkcrDX",
        "outputId": "24990351-0016-42eb-c733-aa78bba2cfc0"
      },
      "source": [
        "#now plot the model\n",
        "y_pred_2=model_2.predict(X_test)\n",
        "plot_prediction(prediction=y_pred_2)\n",
        "model_2.predict([300.])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c509fb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c509fb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[309.99994]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LyrZYG8d1rU",
        "outputId": "f47cede0-7cfd-4e28-935e-5ff26b87feb8"
      },
      "source": [
        "mae_2=mae(y_test,y_pred_2)\n",
        "mse_2=mse(y_test,y_pred_2)\n",
        "mae_2,mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=22.782436>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=522.58435>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BBc36J8eTTB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "79ba24d4-bc27-411a-d350-234e12dc1371"
      },
      "source": [
        "#comparing results of experminent using Panda\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "model_result=[[\"model\",mae_1.numpy(),mse_1.numpy()],\n",
        "              [\"model_2\",mae_2.numpy(),mse_2.numpy()]]\n",
        "\n",
        "all_reuslts=pd.DataFrame(model_result, columns=[\"model\",\"mae\",\"mse\"])\n",
        "all_reuslts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model</td>\n",
              "      <td>22.782436</td>\n",
              "      <td>522.584351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>22.782436</td>\n",
              "      <td>522.584351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        mae         mse\n",
              "0    model  22.782436  522.584351\n",
              "1  model_2  22.782436  522.584351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TowAg-262nlr",
        "outputId": "d7c227b3-88b5-460e-bd25-c8165db5d752"
      },
      "source": [
        "model_1.summary(),model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZngn7GJ3gId"
      },
      "source": [
        "#do your best to minimize the time between the experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTS8pg__3lrI"
      },
      "source": [
        "#tracking your experiment \n",
        "\n",
        "being able to track your experiment reudces time between experiment and deriving results\n",
        "\n",
        "#tensor board\n",
        "a component of tf library to help modeling experiments\n",
        "#weights and bias\n",
        "a tool for tracking all kinds of machine learning experiments (which plug starihgt into tensor board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liONSUem4KIP"
      },
      "source": [
        "# saving our model for application integration\n",
        "\n",
        "two main formats of storing model\n",
        "1. savemodel format\n",
        "2. hdf5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMPaaUFn8sPz",
        "outputId": "68bd89a8-9986-4718-b33d-ffacb49c7aac"
      },
      "source": [
        "#save using savemodel format\n",
        "\n",
        "model_2.save(\"model_2_savemodel_format\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_2_savemodel_format/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51wy-Zb084K2"
      },
      "source": [
        "#the saved_model.pb is a protobuff file \n",
        "#now hierarchal data format\n",
        "#hdf5 is for large data storage\n",
        "\n",
        "model_2.save(\"model_2_hdf5_format.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8TZlYpD9qrz",
        "outputId": "4b3c5592-c6e8-4879-aa68-d1fbe1a5e6b4"
      },
      "source": [
        "#now loading the model back\n",
        "loaded_savedmodel_format=tf.keras.models.load_model(\"/content/model_2_savemodel_format\")\n",
        "loaded_savedmodel_format.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZglTK2K-anf",
        "outputId": "48d9df5b-64c6-4ac2-ade8-3812199c7eb2"
      },
      "source": [
        "#you can remove the content/ and it'd still work\n",
        "#now to confirm if it is actually the same as model_2 \n",
        "#you compare using the same comparison of predicitons as well as mae\n",
        "\n",
        "#now hdf5 formal\n",
        "loaded_h5_fomat=tf.keras.models.load_model(\"/content/model_2_savemodel_format\")\n",
        "loaded_h5_fomat.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lapi2zP_ZD1",
        "outputId": "79bd00a2-1d9e-4902-ae88-e089ef8f30f4"
      },
      "source": [
        "model_2_newpred=model_2.predict(X_test)\n",
        "loaded_h5_fomat_pred=loaded_h5_fomat.predict(X_test)\n",
        "model_2_newpred==loaded_h5_fomat_pred\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f3c5061b4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySOzl7ba_6x4"
      },
      "source": [
        "#to download  the file you can just go to files menu and down files form there\n",
        "#or use code \n",
        "#save it to google drive by connecting google drive and copying it there"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YtwUnq-29of7",
        "outputId": "b907f0ec-e7fd-46be-c44d-82764f0b0a1f"
      },
      "source": [
        "#code to download files from colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/model_2_hdf5_format.h5\") #path here "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4d84880f-ff95-4160-9858-29d3df8678e3\", \"model_2_hdf5_format.h5\", 25536)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqOm1a8u-DQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "K3H8TZxI-O6e",
        "outputId": "e4b755f2-ce44-4f51-9481-2adc1762577a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#to access cp \"path to file\" \"path to drive\"\n",
        "#to see ls \"path in drive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZnWWbP--z6T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3zxVSrU-sxI"
      },
      "source": [
        "#Larger Example\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8ArRTxf_AlH",
        "outputId": "3414824f-188d-4a46-d025-618fc1de5bec"
      },
      "source": [
        "X_train, y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56], dtype=int32)>,\n",
              " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuMxmfZb_Dp5"
      },
      "source": [
        "#import req libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jCcOAC2FDxgU",
        "outputId": "32da5988-73ff-4f92-820c-9c1bd7876f4c"
      },
      "source": [
        "#read the insurance dataset\n",
        "insaurance=pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insaurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd5EXj1-D7nr",
        "outputId": "c7696c92-1e51-4593-86ed-dec19fb883d2"
      },
      "source": [
        "insaurance[\"sex\"], insaurance[\"age\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0       female\n",
              " 1         male\n",
              " 2         male\n",
              " 3         male\n",
              " 4         male\n",
              "          ...  \n",
              " 1333      male\n",
              " 1334    female\n",
              " 1335    female\n",
              " 1336    female\n",
              " 1337    female\n",
              " Name: sex, Length: 1338, dtype: object, 0       19\n",
              " 1       18\n",
              " 2       28\n",
              " 3       33\n",
              " 4       32\n",
              "         ..\n",
              " 1333    50\n",
              " 1334    18\n",
              " 1335    18\n",
              " 1336    21\n",
              " 1337    61\n",
              " Name: age, Length: 1338, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb-snRHEEbio"
      },
      "source": [
        "#we need to convert the nonumerical values into numcerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "9KHtCti5EwQb",
        "outputId": "052931af-00a2-407d-ba9d-6fe3332c03f7"
      },
      "source": [
        "#we use one hot encoding for our catergorical data\n",
        "#padas.get_dummies convert these data into categorical data\n",
        "\n",
        "insaurance_one_hot=pd.get_dummies(insaurance)\n",
        "insaurance_one_hot #top 5 rows tails for bottom 5 rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     bmi  ...  region_southeast  region_southwest\n",
              "0      19  27.900  ...                 0                 1\n",
              "1      18  33.770  ...                 1                 0\n",
              "2      28  33.000  ...                 1                 0\n",
              "3      33  22.705  ...                 0                 0\n",
              "4      32  28.880  ...                 0                 0\n",
              "...   ...     ...  ...               ...               ...\n",
              "1333   50  30.970  ...                 0                 0\n",
              "1334   18  31.920  ...                 0                 0\n",
              "1335   18  36.850  ...                 1                 0\n",
              "1336   21  25.800  ...                 0                 1\n",
              "1337   61  29.070  ...                 0                 0\n",
              "\n",
              "[1338 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52ziPS1StEQ",
        "outputId": "836d26e3-6704-44fd-84fd-917a00291fcd"
      },
      "source": [
        "#this is the shortest way of doing it\n",
        "y=insaurance_one_hot[\"charges\"]\n",
        "X=insaurance_one_hot.drop(\"charges\",axis=1)\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      age     bmi  ...  region_southeast  region_southwest\n",
              " 0      19  27.900  ...                 0                 1\n",
              " 1      18  33.770  ...                 1                 0\n",
              " 2      28  33.000  ...                 1                 0\n",
              " 3      33  22.705  ...                 0                 0\n",
              " 4      32  28.880  ...                 0                 0\n",
              " ...   ...     ...  ...               ...               ...\n",
              " 1333   50  30.970  ...                 0                 0\n",
              " 1334   18  31.920  ...                 0                 0\n",
              " 1335   18  36.850  ...                 1                 0\n",
              " 1336   21  25.800  ...                 0                 1\n",
              " 1337   61  29.070  ...                 0                 0\n",
              " \n",
              " [1338 rows x 11 columns], 0       16884.92400\n",
              " 1        1725.55230\n",
              " 2        4449.46200\n",
              " 3       21984.47061\n",
              " 4        3866.85520\n",
              "            ...     \n",
              " 1333    10600.54830\n",
              " 1334     2205.98080\n",
              " 1335     1629.83350\n",
              " 1336     2007.94500\n",
              " 1337    29141.36030\n",
              " Name: charges, Length: 1338, dtype: float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv_R1W-6Fpqr"
      },
      "source": [
        "\n",
        "#how i did it\n",
        "```\n",
        "y=insaurance_one_hot[\"charges\"]\n",
        "y\n",
        "y_train=y[:1138]\n",
        "y_test=y[1137:]\n",
        "y_train,y_test\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5UbzTp3GXHM"
      },
      "source": [
        "#for features\n",
        "\n",
        "\n",
        "```\n",
        "X=insaurance_one_hot[:]\n",
        "del X [\"charges\"] #its a dictionary type of thing basically\n",
        "\n",
        "X_train=X[:1138]\n",
        "X_test=X[1138:]\n",
        "X_train,X_test\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_FmRL8GRIm1"
      },
      "source": [
        "#you could also do \n",
        "```\n",
        "X=insaurance_one_hot.drop(\"charges\",axis=1)\n",
        "```\n",
        "#also know that sometimes you have  to change the data format into something that can be understood by our neural network\n",
        "\n",
        "#another important way of creating test set is using sk learn\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLOGpmeQRnf5",
        "outputId": "b694c4fd-d10a-4788-b85e-371335791e11"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "len(X), len(X_train),len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUStaef6GzR0",
        "outputId": "f4cf34bc-7e01-4ff9-ce50-0675014c9075"
      },
      "source": [
        "#set seed\n",
        "tf.random.set_seed(42)\n",
        "#build the model\n",
        "insaurance_model=tf.keras.Sequential([\n",
        "                                      tf.keras.layers.Dense(10),\n",
        "                                      tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile the model \n",
        "insaurance_model.compile(loss=[\"mae\"],\n",
        "                          optimizer=tf.keras.optimizers.SGD(),\n",
        "                          metrics=[\"mae\"])\n",
        "#fit the model\n",
        "insaurance_model.fit(X_train,y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 1ms/step - loss: 10200.7270 - mae: 10200.7270\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7718.1919 - mae: 7718.1919\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6983.7824 - mae: 6983.7824\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8083.4829 - mae: 8083.4829\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7793.8446 - mae: 7793.8446\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7618.4107 - mae: 7618.4107\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7678.4977 - mae: 7678.4977\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.4291 - mae: 7780.4291\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7588.8130 - mae: 7588.8130\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7520.6838 - mae: 7520.6838\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8309.7820 - mae: 8309.7820\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.0188 - mae: 7748.0188\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7888.3563 - mae: 7888.3563\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7731.1164 - mae: 7731.1164\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7786.1045 - mae: 7786.1045\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8343.8852 - mae: 8343.8852\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7142.3603 - mae: 7142.3603\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8070.0509 - mae: 8070.0509\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7604.8297 - mae: 7604.8297\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7945.1267 - mae: 7945.1267\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6864.6824 - mae: 6864.6824\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7505.7910 - mae: 7505.7910\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7621.7374 - mae: 7621.7374\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7262.7539 - mae: 7262.7539\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8156.1943 - mae: 8156.1943\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7246.2709 - mae: 7246.2709\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7562.7814 - mae: 7562.7814\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7842.6213 - mae: 7842.6213\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7153.8769 - mae: 7153.8769\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7723.4945 - mae: 7723.4945\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8310.0634 - mae: 8310.0634\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7734.9641 - mae: 7734.9641\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.4651 - mae: 7403.4651\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7482.6278 - mae: 7482.6278\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7198.8921 - mae: 7198.8921\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.1010 - mae: 7484.1010\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7701.6285 - mae: 7701.6285\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6923.6144 - mae: 6923.6144\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7673.7911 - mae: 7673.7911\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7670.9191 - mae: 7670.9191\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7774.5872 - mae: 7774.5872\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7413.0886 - mae: 7413.0886\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7793.8665 - mae: 7793.8665\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7239.3577 - mae: 7239.3577\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7402.6549 - mae: 7402.6549\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7167.7284 - mae: 7167.7284\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7716.9022 - mae: 7716.9022\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7509.9133 - mae: 7509.9133\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7216.6765 - mae: 7216.6765\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7354.2577 - mae: 7354.2577\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7587.3343 - mae: 7587.3343\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7697.7618 - mae: 7697.7618\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.7635 - mae: 7084.7635\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7366.1160 - mae: 7366.1160\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7354.5013 - mae: 7354.5013\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7201.4705 - mae: 7201.4705\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7612.1701 - mae: 7612.1701\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7684.3347 - mae: 7684.3347\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7315.3647 - mae: 7315.3647\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7381.6661 - mae: 7381.6661\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7842.5244 - mae: 7842.5244\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7346.2639 - mae: 7346.2639\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7634.5369 - mae: 7634.5369\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6976.2133 - mae: 6976.2133\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7608.7967 - mae: 7608.7967\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.7896 - mae: 7275.7896\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7244.1635 - mae: 7244.1635\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7553.0939 - mae: 7553.0939\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8028.1948 - mae: 8028.1948\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7150.7139 - mae: 7150.7139\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.5192 - mae: 7137.5192\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6708.9293 - mae: 6708.9293\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7554.2729 - mae: 7554.2729\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7060.4082 - mae: 7060.4082\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7564.8154 - mae: 7564.8154\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7016.7828 - mae: 7016.7828\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7936.9772 - mae: 7936.9772\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6828.1390 - mae: 6828.1390\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6875.0795 - mae: 6875.0795\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6770.6307 - mae: 6770.6307\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7216.2089 - mae: 7216.2089\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7774.2735 - mae: 7774.2735\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7156.2550 - mae: 7156.2550\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7436.0035 - mae: 7436.0035\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6855.7935 - mae: 6855.7935\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7768.8281 - mae: 7768.8281\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7014.5800 - mae: 7014.5800\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7525.7778 - mae: 7525.7778\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6994.6077 - mae: 6994.6077\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7677.9612 - mae: 7677.9612\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7210.0508 - mae: 7210.0508\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.2236 - mae: 7335.2236\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7235.0912 - mae: 7235.0912\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6728.8874 - mae: 6728.8874\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7811.5180 - mae: 7811.5180\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7430.2760 - mae: 7430.2760\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6876.5969 - mae: 6876.5969\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7070.8696 - mae: 7070.8696\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7118.6875 - mae: 7118.6875\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6880.6744 - mae: 6880.6744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ca115f810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VImY4rvOPwd8"
      },
      "source": [
        "#make some functions to reuse MAE and MSE for reuseability\n",
        "\n",
        "def mae(y_true, y_test):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                       y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "\n",
        "def mse(y_true, y_test):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
        "                                       y_pred= tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SbSavqFP-S6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "6258d13d-2b4f-45e4-d5cf-51072c5c8322"
      },
      "source": [
        "#lets create the plotting function\n",
        "#if you feel like you're going to use some functionality in the future\n",
        "#it's better to make it into a funciton\n",
        "\n",
        "def plot_prediction(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     prediction=y_pred):\n",
        "  \"\"\"\n",
        "  Plot training data,test data, predicitions to the ground truth labels\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "  #plt training data\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",label=\"training data\")\n",
        "  #plt test data\n",
        "  plt.scatter(test_data,test_labels,c=\"g\",label=\"test data\")\n",
        "  #plot predicitons in red\n",
        "  plt.scatter(test_data, prediction,c=\"r\",label=\"predicitons\")\n",
        "  #show the legend\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bd7e395819ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0mtest_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                      prediction=y_pred):\n\u001b[0m\u001b[1;32m     10\u001b[0m   \"\"\"\n\u001b[1;32m     11\u001b[0m   \u001b[0mPlot\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicitions\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mground\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UPh43_0Lll7",
        "outputId": "b387d867-0c56-469f-d435-d4e6c8aad4a8"
      },
      "source": [
        "insaurance_model.evaluate(X_test,y_test)\n",
        "#we notice here that somehow its performing better on test data \n",
        "#start to notice patterns in how the data is beingg dealt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3qdvO58Purb"
      },
      "source": [
        "#now we improve our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqkDySCMO7C8"
      },
      "source": [
        "1. add an extra layer with more hidden unit and changge optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBMEmdqRWwoB",
        "outputId": "877a4b93-d8bf-45cc-81c6-e433024779e8"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "#create the model\n",
        "insaurance_model_2=tf.keras.Sequential([\n",
        "                                        tf.keras.layers.Dense(100),\n",
        "                                        tf.keras.layers.Dense(10),\n",
        "                                        tf.keras.layers.Dense(1)\n",
        "])\n",
        "#adding 100 layers in top created an nan model, aka the model is too complex\n",
        "#compile \n",
        "insaurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=[\"mae\"])\n",
        "#fit\n",
        "insaurance_model_2.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13251.7400 - mae: 13251.7400\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12768.7726 - mae: 12768.7726\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12248.2855 - mae: 12248.2855\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12353.0242 - mae: 12353.0242\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11243.3972 - mae: 11243.3972\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9718.5255 - mae: 9718.5255\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8354.8474 - mae: 8354.8474\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7732.2964 - mae: 7732.2964\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.6737 - mae: 7537.6737\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7652.7184 - mae: 7652.7184\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7802.4481 - mae: 7802.4481\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7370.3458 - mae: 7370.3458\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7651.9583 - mae: 7651.9583\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7404.5587 - mae: 7404.5587\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.0614 - mae: 7639.0614\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7569.4714 - mae: 7569.4714\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6946.3936 - mae: 6946.3936\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.7241 - mae: 7137.7241\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7165.3119 - mae: 7165.3119\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7063.6223 - mae: 7063.6223\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6472.3189 - mae: 6472.3189\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6674.0546 - mae: 6674.0546\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7112.2982 - mae: 7112.2982\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6838.1526 - mae: 6838.1526\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.9558 - mae: 7496.9558\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6718.1682 - mae: 6718.1682\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7107.2977 - mae: 7107.2977\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7357.2010 - mae: 7357.2010\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6668.5721 - mae: 6668.5721\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7119.4991 - mae: 7119.4991\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7360.1235 - mae: 7360.1235\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6817.2566 - mae: 6817.2566\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6991.0289 - mae: 6991.0289\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6829.4905 - mae: 6829.4905\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6895.2916 - mae: 6895.2916\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6762.5129 - mae: 6762.5129\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6910.4815 - mae: 6910.4815\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6405.0325 - mae: 6405.0325\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6799.7921 - mae: 6799.7921\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6696.0544 - mae: 6696.0544\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6632.0484 - mae: 6632.0484\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6501.1589 - mae: 6501.1589\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6518.8881 - mae: 6518.8881\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6287.3744 - mae: 6287.3744\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6331.2561 - mae: 6331.2561\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6080.3169 - mae: 6080.3169\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6665.8195 - mae: 6665.8195\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6424.2352 - mae: 6424.2352\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6154.8287 - mae: 6154.8287\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6426.9840 - mae: 6426.9840\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6338.3259 - mae: 6338.3259\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6335.6011 - mae: 6335.6011\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5995.7962 - mae: 5995.7962\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6431.7972 - mae: 6431.7972\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6224.0661 - mae: 6224.0661\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6289.4112 - mae: 6289.4112\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6578.3136 - mae: 6578.3136\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6365.6013 - mae: 6365.6013\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5914.7983 - mae: 5914.7983\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6239.8723 - mae: 6239.8723\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6751.6415 - mae: 6751.6415\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6350.5861 - mae: 6350.5861\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6374.7378 - mae: 6374.7378\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5877.7617 - mae: 5877.7617\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6260.5318 - mae: 6260.5318\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6007.1747 - mae: 6007.1747\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6106.7938 - mae: 6106.7938\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6035.6668 - mae: 6035.6668\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6523.5435 - mae: 6523.5435\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5708.9528 - mae: 5708.9528\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6110.2170 - mae: 6110.2170\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5773.3151 - mae: 5773.3151\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6297.5183 - mae: 6297.5183\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6112.9393 - mae: 6112.9393\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6449.7250 - mae: 6449.7250\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5688.1448 - mae: 5688.1448\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6402.3397 - mae: 6402.3397\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5499.5553 - mae: 5499.5553\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5108.3478 - mae: 5108.3478\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5226.6397 - mae: 5226.6397\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5817.3261 - mae: 5817.3261\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6548.7323 - mae: 6548.7323\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5722.6891 - mae: 5722.6891\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5570.2336 - mae: 5570.2336\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5121.8587 - mae: 5121.8587\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5889.9362 - mae: 5889.9362\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5472.2751 - mae: 5472.2751\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5770.0215 - mae: 5770.0215\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5392.7422 - mae: 5392.7422\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5951.3922 - mae: 5951.3922\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5577.1110 - mae: 5577.1110\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5633.8429 - mae: 5633.8429\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5209.0318 - mae: 5209.0318\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5018.4434 - mae: 5018.4434\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5419.2086 - mae: 5419.2086\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5547.8981 - mae: 5547.8981\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4931.7091 - mae: 4931.7091\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4912.5433 - mae: 4912.5433\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4650.0259 - mae: 4650.0259\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4770.1368 - mae: 4770.1368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c9e9beed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiir8hM4XZbm",
        "outputId": "d4304b05-e490-42d5-8e57-54d46849973e"
      },
      "source": [
        "#evaluate\n",
        "insaurance_model_2.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EODUWN70Ye78"
      },
      "source": [
        "2. Now with the same model, train for longer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKJsQLv4Y7az",
        "outputId": "cdd1f8e5-61c1-4f3a-8200-1b4150f8c8f8"
      },
      "source": [
        "#set seed\n",
        "tf.random.set_seed(42)\n",
        "#create model\n",
        "insaurance_model_3=tf.keras.Sequential([\n",
        "                                        tf.keras.layers.Dense(100),\n",
        "                                        tf.keras.layers.Dense(10),\n",
        "                                        tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile model\n",
        "insaurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=[\"mae\"])\n",
        "#fit model\n",
        "history=insaurance_model_3.fit(X_train,y_train,epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13251.7400 - mae: 13251.7400\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12768.7726 - mae: 12768.7726\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12248.2855 - mae: 12248.2855\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 12353.0242 - mae: 12353.0242\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11243.3972 - mae: 11243.3972\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9718.5255 - mae: 9718.5255\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8354.8474 - mae: 8354.8474\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7732.2964 - mae: 7732.2964\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.6737 - mae: 7537.6737\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7652.7184 - mae: 7652.7184\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7802.4481 - mae: 7802.4481\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7370.3458 - mae: 7370.3458\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7651.9583 - mae: 7651.9583\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7404.5587 - mae: 7404.5587\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.0614 - mae: 7639.0614\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.4714 - mae: 7569.4714\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6946.3936 - mae: 6946.3936\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7137.7241 - mae: 7137.7241\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7165.3119 - mae: 7165.3119\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7063.6223 - mae: 7063.6223\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6472.3189 - mae: 6472.3189\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6674.0546 - mae: 6674.0546\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7112.2982 - mae: 7112.2982\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6838.1526 - mae: 6838.1526\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.9558 - mae: 7496.9558\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6718.1682 - mae: 6718.1682\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7107.2977 - mae: 7107.2977\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7357.2010 - mae: 7357.2010\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6668.5721 - mae: 6668.5721\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7119.4991 - mae: 7119.4991\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7360.1235 - mae: 7360.1235\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6817.2566 - mae: 6817.2566\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6991.0289 - mae: 6991.0289\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6829.4905 - mae: 6829.4905\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6895.2916 - mae: 6895.2916\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6762.5129 - mae: 6762.5129\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6910.4815 - mae: 6910.4815\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6405.0325 - mae: 6405.0325\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6799.7921 - mae: 6799.7921\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6696.0544 - mae: 6696.0544\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6632.0484 - mae: 6632.0484\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6501.1589 - mae: 6501.1589\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6518.8881 - mae: 6518.8881\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6287.3744 - mae: 6287.3744\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6331.2561 - mae: 6331.2561\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6080.3169 - mae: 6080.3169\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6665.8195 - mae: 6665.8195\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6424.2352 - mae: 6424.2352\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6154.8287 - mae: 6154.8287\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6426.9840 - mae: 6426.9840\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6338.3259 - mae: 6338.3259\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6335.6011 - mae: 6335.6011\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.7962 - mae: 5995.7962\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6431.7972 - mae: 6431.7972\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6224.0661 - mae: 6224.0661\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6289.4112 - mae: 6289.4112\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6578.3136 - mae: 6578.3136\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6365.6013 - mae: 6365.6013\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5914.7983 - mae: 5914.7983\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6239.8723 - mae: 6239.8723\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6751.6415 - mae: 6751.6415\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6350.5861 - mae: 6350.5861\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6374.7378 - mae: 6374.7378\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5877.7617 - mae: 5877.7617\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6260.5318 - mae: 6260.5318\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6007.1747 - mae: 6007.1747\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6106.7938 - mae: 6106.7938\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6035.6668 - mae: 6035.6668\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6523.5435 - mae: 6523.5435\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5708.9528 - mae: 5708.9528\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6110.2170 - mae: 6110.2170\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5773.3151 - mae: 5773.3151\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6297.5183 - mae: 6297.5183\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6112.9393 - mae: 6112.9393\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6449.7250 - mae: 6449.7250\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5688.1448 - mae: 5688.1448\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 6402.3397 - mae: 6402.3397\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5499.5553 - mae: 5499.5553\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5108.3478 - mae: 5108.3478\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5226.6397 - mae: 5226.6397\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5817.3261 - mae: 5817.3261\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6548.7323 - mae: 6548.7323\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5722.6891 - mae: 5722.6891\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5570.2336 - mae: 5570.2336\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5121.8587 - mae: 5121.8587\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5889.9362 - mae: 5889.9362\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5472.2751 - mae: 5472.2751\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5770.0215 - mae: 5770.0215\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5392.7422 - mae: 5392.7422\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5951.3922 - mae: 5951.3922\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5577.1110 - mae: 5577.1110\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5633.8429 - mae: 5633.8429\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5209.0318 - mae: 5209.0318\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5018.4434 - mae: 5018.4434\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5419.2086 - mae: 5419.2086\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 5547.8981 - mae: 5547.8981\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4931.7091 - mae: 4931.7091\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4912.5433 - mae: 4912.5433\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4650.0259 - mae: 4650.0259\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4770.1368 - mae: 4770.1368\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4909.3405 - mae: 4909.3405\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4673.0495 - mae: 4673.0495\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4396.5531 - mae: 4396.5531\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4917.1084 - mae: 4917.1084\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4314.7778 - mae: 4314.7778\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4739.7995 - mae: 4739.7995\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4745.8093 - mae: 4745.8093\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4517.0400 - mae: 4517.0400\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4803.4275 - mae: 4803.4275\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4702.8919 - mae: 4702.8919\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4289.6146 - mae: 4289.6146\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4062.5322 - mae: 4062.5322\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3978.4756 - mae: 3978.4756\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4152.9214 - mae: 4152.9214\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4003.9165 - mae: 4003.9165\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4288.2785 - mae: 4288.2785\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3860.9309 - mae: 3860.9309\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3865.8638 - mae: 3865.8638\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3953.7542 - mae: 3953.7542\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4055.4669 - mae: 4055.4669\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4136.1248 - mae: 4136.1248\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3805.4186 - mae: 3805.4186\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.5202 - mae: 3729.5202\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3653.3789 - mae: 3653.3789\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4047.0974 - mae: 4047.0974\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3759.8391 - mae: 3759.8391\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3898.7483 - mae: 3898.7483\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3728.9218 - mae: 3728.9218\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4054.4523 - mae: 4054.4523\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3811.9230 - mae: 3811.9230\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3840.0032 - mae: 3840.0032\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4002.2322 - mae: 4002.2322\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4039.5692 - mae: 4039.5692\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3874.6315 - mae: 3874.6315\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3851.9765 - mae: 3851.9765\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3716.1255 - mae: 3716.1255\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.7132 - mae: 3771.7132\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4019.1487 - mae: 4019.1487\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3714.7945 - mae: 3714.7945\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3735.7563 - mae: 3735.7563\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3858.8476 - mae: 3858.8476\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3625.0085 - mae: 3625.0085\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3835.1521 - mae: 3835.1521\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3868.1936 - mae: 3868.1936\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4044.2481 - mae: 4044.2481\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3948.1645 - mae: 3948.1645\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3696.6694 - mae: 3696.6694\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3497.7141 - mae: 3497.7141\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.5157 - mae: 3636.5157\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3824.4876 - mae: 3824.4876\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3805.8298 - mae: 3805.8298\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3755.0754 - mae: 3755.0754\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3716.7277 - mae: 3716.7277\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3894.3153 - mae: 3894.3153\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3651.1834 - mae: 3651.1834\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3542.4872 - mae: 3542.4872\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3542.7571 - mae: 3542.7571\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3921.3213 - mae: 3921.3213\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3773.9635 - mae: 3773.9635\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3836.4512 - mae: 3836.4512\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3695.3159 - mae: 3695.3159\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3842.3962 - mae: 3842.3962\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3436.4965 - mae: 3436.4965\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3658.1668 - mae: 3658.1668\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3724.9990 - mae: 3724.9990\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3876.5262 - mae: 3876.5262\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4017.7594 - mae: 4017.7594\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3752.5265 - mae: 3752.5265\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3595.9144 - mae: 3595.9144\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3880.7918 - mae: 3880.7918\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3588.6998 - mae: 3588.6998\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3788.0718 - mae: 3788.0718\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3816.2179 - mae: 3816.2179\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.2578 - mae: 3762.2578\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3877.9812 - mae: 3877.9812\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3795.1465 - mae: 3795.1465\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3768.2689 - mae: 3768.2689\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3567.2376 - mae: 3567.2376\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3471.1047 - mae: 3471.1047\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 4114.2342 - mae: 4114.2342\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3853.8357 - mae: 3853.8357\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3778.6590 - mae: 3778.6590\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3474.2507 - mae: 3474.2507\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.6951 - mae: 3624.6951\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3491.3103 - mae: 3491.3103\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3824.2027 - mae: 3824.2027\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3889.5553 - mae: 3889.5553\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3916.9766 - mae: 3916.9766\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3449.6390 - mae: 3449.6390\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3790.5261 - mae: 3790.5261\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3899.9987 - mae: 3899.9987\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3676.4644 - mae: 3676.4644\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.0237 - mae: 3766.0237\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3871.3434 - mae: 3871.3434\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3423.9755 - mae: 3423.9755\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.7101 - mae: 3567.7101\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3950.4742 - mae: 3950.4742\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3620.9258 - mae: 3620.9258\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 3628.1823 - mae: 3628.1823\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3810.1321 - mae: 3810.1321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcaRAAPNZkHI",
        "outputId": "c64c6797-100e-435a-c349-4946e80033eb"
      },
      "source": [
        "#evaluate the mode\n",
        "insaurance_model_3.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ttwumhloaDFB",
        "outputId": "72b42689-b9c4-45f3-f0f2-3bd54b6230c8"
      },
      "source": [
        "#plot history (also known as loss curve or training curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDPNVVW8aUcD"
      },
      "source": [
        "#how long should you train for?\n",
        "#it depends on t he problem\n",
        "#earlystoppingcall back is used for that\n",
        "#it is a tensor flow component taht you can add to your model which stops trainin when it stops improving a certain metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6qYcYRZbbmD"
      },
      "source": [
        "#another way of pre processing gdata and (normalization and standardization) neural netwrok prefer normalization\n",
        "\n",
        "normalization is chaning the values of the numeric columns down to a common scale, without distorting differences in the ranges of value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "L-kLX7PA7Wrv",
        "outputId": "34ccc4e8-3172-4c1d-9d9b-bdb2b92b0f8f"
      },
      "source": [
        "X[\"age\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1cbc93af10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "NQmTY4097DQI",
        "outputId": "9fe2ef01-6045-4a62-e51e-04c13e164e15"
      },
      "source": [
        "X[\"bmi\"].plot(kind=\"hist\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c9f985150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNVKlD6t7-3-"
      },
      "source": [
        "#you can notice  that the type of data is different, but what if we  wanted to change all these value between 0 and 1 that is what normalization is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b0DRWsk8Ql2"
      },
      "source": [
        "typically scale features refers to normalization **we use the scikit-learn function MinMaxScalar** it converts all wvalues between 0 and 1 while preserving original distribution\n",
        "\n",
        "**standardization scikit-learn funcntion is StandardScalar** it transforms a feature to have close to normal distribution(caution: it reduces theh effect of outliers, that means take the age graph, the effect of age 20 will be drastically reomove if you use normalize it), basicaly it removes the mean and divides each value by standard diviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qpy4yS0D8z-o",
        "outputId": "17ec49f4-d0e7-44e9-8f95-58631cee4c0a"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#read insaurance dataframe\n",
        "insaurancne=pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insaurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jydtpzsi-LNi"
      },
      "source": [
        "#now import scikit learn\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#create a column transformer\n",
        "ct=make_column_transformer(\n",
        "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]),\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\",\"region\"])\n",
        "#handler_uknown refers that any columns that the one hot encnoder doesn't know \n",
        "#just ignore them instead\n",
        ")\n",
        "\n",
        "#create X&y\n",
        "X=insaurance.drop(\"charges\",axis=1)\n",
        "y=insaurance[\"charges\"]\n",
        "\n",
        "#define test and train sets\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=42)\n",
        "\n",
        "#fit the column transfomer to our training data\n",
        "ct.fit(X_train)\n",
        "#we  only fit the train data because the test data has not been seen by the sys\n",
        "#transformer training and test data with normalization (minmaxscalar) and one hotencoder\n",
        "X_train_normal=ct.transform(X_train)\n",
        "X_test_normal=ct.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDVk7gQ-55j",
        "outputId": "c8605223-3062-4fc6-8147-ce1d3309686a"
      },
      "source": [
        "#what does the data look like now\n",
        "X_train_normal[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RzaGftpDVm0",
        "outputId": "491e8c99-3cb7-4953-93b0-59417a50f996"
      },
      "source": [
        "X_train.loc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_-sg7NiBvND",
        "outputId": "fb6ebc03-d31c-494c-ff90-f5577c240501"
      },
      "source": [
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaNLXHDmCilD"
      },
      "source": [
        "#Our  data has been normalized and one  hot encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuI0KYr3Ct5u",
        "outputId": "95992d2a-0850-4be6-952a-3103e4b086cf"
      },
      "source": [
        "#no lets make our model again\n",
        "tf.random.set_seed(42)\n",
        "#create model\n",
        "insaurance_model_4=tf.keras.Sequential([\n",
        "                                        tf.keras.layers.Dense(100),\n",
        "                                        tf.keras.layers.Dense(10),\n",
        "                                        tf.keras.layers.Dense(1)\n",
        "])\n",
        "#compile\n",
        "insaurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=[\"mae\"])\n",
        "#fit model\n",
        "history=insaurance_model_4.fit(X_train_normal,y_train,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 13296.4671 - mae: 13296.4671\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12948.4245 - mae: 12948.4245\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12705.2201 - mae: 12705.2201\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13369.7395 - mae: 13369.7395\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13230.8567 - mae: 13230.8567\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12995.1999 - mae: 12995.1999\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12876.1059 - mae: 12876.1059\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13004.0395 - mae: 13004.0395\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12508.0465 - mae: 12508.0465\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12304.9941 - mae: 12304.9941\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12190.6080 - mae: 12190.6080\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 10948.1238 - mae: 10948.1238\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11033.2710 - mae: 11033.2710\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10209.3786 - mae: 10209.3786\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9943.5374 - mae: 9943.5374\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9393.3773 - mae: 9393.3773\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8554.0274 - mae: 8554.0274\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8463.0888 - mae: 8463.0888\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8238.9919 - mae: 8238.9919\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7992.1423 - mae: 7992.1423\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7246.4891 - mae: 7246.4891\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7520.6745 - mae: 7520.6745\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7862.2013 - mae: 7862.2013\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7617.0075 - mae: 7617.0075\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8118.1869 - mae: 8118.1869\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7381.5776 - mae: 7381.5776\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7759.2990 - mae: 7759.2990\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7961.3148 - mae: 7961.3148\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7357.1594 - mae: 7357.1594\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7670.5824 - mae: 7670.5824\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7833.2158 - mae: 7833.2158\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7408.4353 - mae: 7408.4353\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7603.6621 - mae: 7603.6621\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7385.2734 - mae: 7385.2734\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7340.4551 - mae: 7340.4551\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7276.7009 - mae: 7276.7009\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7342.1807 - mae: 7342.1807\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6918.2718 - mae: 6918.2718\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7252.1240 - mae: 7252.1240\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7029.9498 - mae: 7029.9498\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6984.8112 - mae: 6984.8112\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.6928 - mae: 6884.6928\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6755.5828 - mae: 6755.5828\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6608.4541 - mae: 6608.4541\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6537.6250 - mae: 6537.6250\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6454.2749 - mae: 6454.2749\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6729.0266 - mae: 6729.0266\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6517.0466 - mae: 6517.0466\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6209.9380 - mae: 6209.9380\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6433.2527 - mae: 6433.2527\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.4749 - mae: 6253.4749\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6122.7599 - mae: 6122.7599\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5797.8437 - mae: 5797.8437\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6036.6884 - mae: 6036.6884\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5688.6436 - mae: 5688.6436\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5664.2595 - mae: 5664.2595\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5857.4061 - mae: 5857.4061\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5509.3852 - mae: 5509.3852\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5316.6016 - mae: 5316.6016\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5322.8677 - mae: 5322.8677\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5458.1975 - mae: 5458.1975\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5230.6231 - mae: 5230.6231\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5084.5996 - mae: 5084.5996\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4677.8217 - mae: 4677.8217\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4707.1110 - mae: 4707.1110\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4361.7458 - mae: 4361.7458\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4333.7879 - mae: 4333.7879\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4294.6888 - mae: 4294.6888\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4365.7155 - mae: 4365.7155\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3931.4924 - mae: 3931.4924\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4040.8881 - mae: 4040.8881\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.7781 - mae: 3725.7781\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4041.0183 - mae: 4041.0183\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3849.4077 - mae: 3849.4077\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4063.8180 - mae: 4063.8180\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.6083 - mae: 3594.6083\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3877.1156 - mae: 3877.1156\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3571.6357 - mae: 3571.6357\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3272.2002 - mae: 3272.2002\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3333.3793 - mae: 3333.3793\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3560.1417 - mae: 3560.1417\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4082.1635 - mae: 4082.1635\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3690.6050 - mae: 3690.6050\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.1416 - mae: 3491.1416\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3196.7644 - mae: 3196.7644\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.4115 - mae: 3696.4115\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3584.8877 - mae: 3584.8877\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3717.8066 - mae: 3717.8066\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3437.4367 - mae: 3437.4367\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3799.4690 - mae: 3799.4690\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.1360 - mae: 3660.1360\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4218 - mae: 3743.4218\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3536.3569 - mae: 3536.3569\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3439.5847 - mae: 3439.5847\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3570.7316 - mae: 3570.7316\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3734.5113 - mae: 3734.5113\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3444.5726 - mae: 3444.5726\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3465.0855 - mae: 3465.0855\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3225.0306 - mae: 3225.0306\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3421.0633 - mae: 3421.0633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkHtPvKGEgmm",
        "outputId": "d9c2b658-1472-4dbd-8cd6-8b8ce764e1bb"
      },
      "source": [
        "insaurance_model_4.evaluate(X_test_normal,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ZahjI1K9EmaI",
        "outputId": "ca6bcf5a-22a8-42a2-864f-819fcea52641"
      },
      "source": [
        "pd.DataFrame(history.history).plot()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5d3/8fd3JhtLWINECEvYZQdDCOKCooAr7ktrxd0+9Skurdal/XWxj9Vqa22tqBUVWzfcKlURl2rVmgBh30mAAEGWECAImJCZuX9/zIGmAhKGJCeZfF7XNdfMuec+c773dTQfzm7OOURERGIR8LsAERFpuBQiIiISM4WIiIjETCEiIiIxU4iIiEjMEvwuoK6lpaW5rl27+l2GiEiDMmfOnK3OuXbfbG90IdK1a1fy8/P9LkNEpEExs7UHa9fuLBERiZlCREREYqYQERGRmDW6YyIiIrGqrKykuLiY8vJyv0upNSkpKWRkZJCYmFit/goREZFqKi4uJjU1la5du2JmfpdT45xzlJaWUlxcTGZmZrXm0e4sEZFqKi8vp23btnEZIABmRtu2bY9oS0shIiJyBOI1QPY50vFpd1Y15b10P1Tswpq0JNikJSltOpDWpS/HdMgkEAz6XZ6IiC8UItXUvuBlMiMHXmtT4RJZm5hJaYdRpA05l+4DRypURKTWNG/enF27dvldxn4KkWrK/H8LKf96N7vKtrFnZyk7t6xj98YCXOkqWm+dw/C1fyGw7im+nNae4oE/ZOg5N5GQmOR32SIitUohcgRSmjQjpUkzSO8EvQb/13fbtmxg1Rd/p9WiZ8he8FPWLZpE6fCfMGTsBJ+qFZF45pzjzjvvZPr06ZgZP/3pT7nsssvYuHEjl112GTt37iQUCjFp0iROOOEErrvuOvLz8zEzrr32Wm677bYaqUMhUkPaHNORNuffjDvvf5j7wQu0mflbhuROJG/V52Td8GdtlYjEmV/+YwlLv9xZo7/Zt0MLfn5uv2r1feONN5g/fz4LFixg69atDBs2jJNPPpkXX3yRsWPHcu+99xIOh9mzZw/z589nw4YNLF68GIAdO3bUWM06O6uGWSDA0LHfI+PuOeQdcyk5W6ay7OExlJVu9rs0EYkjn3/+OVdccQXBYJD27dtzyimnMHv2bIYNG8azzz7LL37xCxYtWkRqairdunVj9erV/PCHP+S9996jRYsWNVaHtkRqSUJiEjk/+Auz3hzA4Pm/ZMtjp1B50wekpXfyuzQRqQHV3WKoayeffDKffvop77zzDldffTW33347V111FQsWLGDGjBk88cQTTJ06lWeeeaZGlqctkVqWfcFEVp31Im0jpZQ+fTHle+rPWRUi0nCddNJJvPLKK4TDYUpKSvj000/Jzs5m7dq1tG/fnhtuuIHrr7+euXPnsnXrViKRCBdddBG//vWvmTt3bo3VoS2ROnDc8LHM2/EwQ3InMmfS9xh62+tYQPktIrG74IILyM3NZdCgQZgZv/3tb0lPT2fKlCk89NBDJCYm0rx5c55//nk2bNjANddcQyQSAeA3v/lNjdVhzrka+7GGICsry/n1UKrcKfcyYs1j5Ha6gRHXPexLDSISu2XLlnHcccf5XUatO9g4zWyOcy7rm331z+E6lPO9+5jV6ixGrP8LS/79jt/liIgcNYVIHbJAgIE3/oUN1p7Uj+6gonyP3yWJiBwVhUgdS2nanNKT76dzZANzX/ql3+WIiBwVhYgPBp56MXOaj2Jo0WTWFy7yuxwRkZgpRHzS+TuPspcEdrz6Q5x3xoSISEOjEPFJuw5dWdJnIgMq5rHwk9f8LkdEJCYKER8NvfB2NpFGUu4f/C5FRCQmChEfJSWnUNT7Wo6rXMKymTP8LkdE5IgpRHw26LyJbKcFez/RxYci8u2Kioro06cPV199Nb169eK73/0uH374ISNHjqRnz57MmjWLWbNmMWLECIYMGcIJJ5zAihUrAAiHw9xxxx0MGzaMgQMH8uSTT9ZITbrtic+aNEtlftfvMqJoEqsW5dF9QI7fJYlIdUy/CzbV8NmV6QPgzAe+tUthYSGvvvoqzzzzDMOGDePFF1/k888/Z9q0adx///08//zzfPbZZyQkJPDhhx9yzz338PrrrzN58mRatmzJ7NmzqaioYOTIkYwZM4bMzMyjKlkhUg/0Hf9jdv3hOXa8/yAMeNPvckSkHsvMzGTAgAEA9OvXj9GjR2NmDBgwgKKiIsrKypgwYQIFBQWYGZWVlQC8//77LFy4kNdei57IU1ZWRkFBgUIkHrRsnUZuh4vI/vIFNqxeQsdu9fMW0yJSxWG2GGpLcnLy/s+BQGD/dCAQIBQK8bOf/YxTTz2VN998k6KiIkaNGgVEn4T4pz/9ibFjx9ZoPTomUk/0OPcOANZ99JTPlYhIQ1ZWVkbHjh0BeO655/a3jx07lkmTJu3fMlm5ciW7d+8+6uUpROqJdh26srjpMLpvmEY4FPK7HBFpoO68807uvvtuhgwZQqjK35Lrr7+evn37MnToUPr3789NN930X9/HSreCr0fmTn+WoTNvZdGpzzLglAv9LkdEvkG3gq/DW8Gb2TNmtsXMFldpe8jMlpvZQjN708xaVfnubjMrNLMVZja2Svs4r63QzO6q0p5pZjO99lfMLKm2xlJX+p16GTtozt78v/pdiohItdTm7qzngHHfaPsA6O+cGwisBO4GMLO+wOVAP2+ex80saGZB4M/AmUBf4AqvL8CDwCPOuR7AduC6WhxLnUhOacqKtLH03/kZZdtK/C5HROSwai1EnHOfAtu+0fa+c27fTrg8IMP7PB542TlX4ZxbAxQC2d6r0Dm32jm3F3gZGG9mBpwG7Lvp1BTg/NoaS11qe9K1JFslyz981u9SROQg4v0QwJGOz88D69cC073PHYH1Vb4r9toO1d4W2FElkPa1N3jdB5zAmkBXWq981e9SROQbUlJSKC0tjdsgcc5RWlpKSkpKtefx5ToRM7sXCAEv1NHybgRuBOjcuXNdLDJmFgiwuftF5BT8jqJl+XQ97oDjWCLik4yMDIqLiykpid/dzSkpKWRkZBy+o6fOQ8TMrgbOAUa7/8T5BqBTlW4ZXhuHaC8FWplZgrc1UrX/AZxzTwFPQfTsrBoYRq3qMfoawit/z8YvXlKIiNQjiYmJR32Fd7yp091ZZjYOuBM4zzlX9QHj04DLzSzZzDKBnsAsYDbQ0zsTK4nowfdpXvh8DFzszT8BeKuuxlHb0tI7sTy5P+kbPvC7FBGRb1Wbp/i+BOQCvc2s2MyuAx4DUoEPzGy+mT0B4JxbAkwFlgLvATc758LeVsb/AjOAZcBUry/AT4DbzayQ6DGSybU1Fj981XUcmZG1rC9Y4HcpIiKHpIsN66lN6wpIfyaL3G4TGXHVfX6XIyKNXJ1fbChHJ71zTwoSetJ23Xt+lyIickgKkXpsa6cx9AqtZNP6Qr9LERE5KIVIPdZxxKUAFH0+1edKREQOTiFSj3XuNZiiQCdS10w/fGcRER8oROq5jR3OoE/FIrZtOeRlMCIivlGI1HPthl1M0ByrPn/t8J1FROqYQqSe6z5gBJtII6Fwht+liIgcQCFSz1kgwNq2J9J7dz7lXx/9oyxFRGqSQqQBSOl/Dk2tgpV5OsAuIvWLQqQB6J1zFntcMl8vecfvUkRE/otCpAFIadKMFc2Op8vWz3CRiN/liIjspxBpICq7jyWdEtYsne13KSIi+ylEGohuIy4AYEt+3NzxXkTigEKkgUjr0IWVCb1oXfyR36WIiOynEGlASjueRs/KFZRuLva7FBERQCHSoLQbeh4Bc6z64k2/SxERARQiDUr3ASPYTFtdvS4i9YZCpAGxQICitifRZ9csXb0uIvWCQqSBSel3tq5eF5F6QyHSwPQecbauXheRekMh0sBEr17PosvWT3X1uoj4TiHSAIV6jCWdraxeMsvvUkSkkVOINECZJ1xIxBlb8nWqr4j4SyHSAKWld6IgsRdtN/zT71JEpJFTiDRQ2zJOo1doJVs3rfO7FBFpxBQiDVT7rOgNGVf/+3WfKxGRxkwh0kBl9h3GRtqRuOp9v0sRkUZMIdJAWSDAurST6bM7n/I9u/wuR0QaKYVIA9Z04Lk0sb0sz33b71JEpJFSiDRgvYefyS7XhL1LFCIi4g+FSAOWlJzCytRsum37jEg47Hc5ItIIKUQauEivM0ljB4ULPvO7FBFphGotRMzsGTPbYmaLq7S1MbMPzKzAe2/ttZuZ/dHMCs1soZkNrTLPBK9/gZlNqNJ+vJkt8ub5o5lZbY2lPus58kJCLkDpXD17XUTqXm1uiTwHjPtG213AR865nsBH3jTAmUBP73UjMAmioQP8HBgOZAM/3xc8Xp8bqsz3zWU1Ci3btmdlcj/af6mr10Wk7tVaiDjnPgW2faN5PDDF+zwFOL9K+/MuKg9oZWbHAmOBD5xz25xz24EPgHHedy2cc3nOOQc8X+W3Gp2dnU+nW6SIL4tW+F2KiDQydX1MpL1zbqP3eRPQ3vvcEVhfpV+x1/Zt7cUHaT8oM7vRzPLNLL+kpOToRlAPdcy5CIB1ubp6XUTqlm8H1r0tCFdHy3rKOZflnMtq165dXSyyTnXqMYC1gQyaF+nZ6yJSt+o6RDZ7u6Lw3rd47RuATlX6ZXht39aecZD2RuvL9NH0KV/Ijq2b/C5FRBqRug6RacC+M6wmAG9Vab/KO0srByjzdnvNAMaYWWvvgPoYYIb33U4zy/HOyrqqym81SmnZl5BgEVZ+NtXvUkSkEanNU3xfAnKB3mZWbGbXAQ8AZ5hZAXC6Nw3wLrAaKAT+AvwAwDm3DbgPmO29fuW14fV52ptnFTC9tsbSEPQYOJKNtCN5pa5eF5G6k1BbP+ycu+IQX40+SF8H3HyI33kGeOYg7flA/6OpMZ5YIMDa9qMZuuk1virbRmrLNn6XJCKNgK5YjyMth15IkoVY8bnO0hKRuqEQiSO9s05nK60ILJvmdyki0kgoROJIIBhkVdtR9Plqpp4xIiJ1QiESZ5oOupCmVsGyz//udyki0ggoROJMn5xxlNGM8GKFiIjUPoVInElMSmZF61PpW/Ype3aV+V2OiMQ5hUgcap59JU2tgqX/fMnvUkQkzilE4lCf7DFspB1JS1/1uxQRiXMKkTgUCAYp6ng2/b6ew9Yv1/pdjojEMYVInOpw8jUEzVH48XN+lyIicUwhEqe69B5MQUJP2q3WWVoiUnsUInGstPsFdA+vZs3S2X6XIiJxSiESx3qeNoGQC7Dps+f8LkVE4pRCJI61bZ/B4qbZ9Nz4NhXle/wuR0TikEIkzgVzbiKNHSx871m/SxGROKQQiXP9TzqfokAnWi+ajItE/C5HROKMQiTOWSDAlr7X0iO8imUzZ/hdjojEGYVIIzDwrBvZTioVnz/mdykiEmcUIo1AStPmLO94EYN2/ZsNq5f5XY6IxJFqhYiZ3WJmLSxqspnNNbMxtV2c1JzuZ91KmADrZ/zB71JEJI5Ud0vkWufcTmAM0Br4HvBArVUlNe6YjpksaHkqAze9ydZN6/0uR0TiRHVDxLz3s4C/OueWVGmTBqL9eb8gkRCrXvt/fpciInGiuiEyx8zeJxoiM8wsFdD5og1Mpx4DmJt2LkNL3qK4cLHf5YhIHKhuiFwH3AUMc87tARKBa2qtKqk13S+5j0oS2PzWz/wuRUTiQHVDZASwwjm3w8yuBH4K6NmrDVBaemcWdPoux3/1Twrmf+Z3OSLSwFU3RCYBe8xsEPAjYBXwfK1VJbWq/yU/i143Mv2nuopdRI5KdUMk5JxzwHjgMefcn4HU2itLalNqyzas7DuR/hXzmfXaw36XIyINWHVD5Cszu5voqb3vmFmA6HERaaCGXfQjFqZkMXDJQ6xdMd/vckSkgapuiFwGVBC9XmQTkAE8VGtVSa0LBIN0uOoZyi2ZyqnXsrei3O+SRKQBqlaIeMHxAtDSzM4Byp1zOibSwKV16ELRCQ/QI7yKOc/d4Xc5ItIAVfe2J5cCs4BLgEuBmWZ2cW0WJnVjyJgrmdXmXEZsfJ68F3/tdzki0sBUd3fWvUSvEZngnLsKyAZ0oUGcGHzT08xtdhI5Kx8id8q9fpcjIg1IdUMk4JzbUmW69AjmPYCZ3WZmS8xssZm9ZGYpZpZpZjPNrNDMXjGzJK9vsjdd6H3ftcrv3O21rzCzsbHW09glJacw8NY3yG9xOiPWPEbe07fr1F8RqZbqBsF7ZjbDzK42s6uBd4B3Y1mgmXUEJgJZzrn+QBC4HHgQeMQ51wPYTvQqebz37V77I14/zKyvN18/YBzwuJkFY6lJICExiSETX2FWq7PIKZ7MwofGUrq52O+yRKSeq+6B9TuAp4CB3usp59xPjmK5CUATM0sAmgIbgdOA17zvpwDne5/He9N43482M/PaX3bOVTjn1gCFRHezSYyCCQkMm/gCM/vcRZ8982DSCSz4+FW/yxKReqzau6Scc6875273Xm/GukDn3AbgYWAd0fAoA+YAO5xzIa9bMdDR+9wRWO/NG/L6t63afpB5/ouZ3Whm+WaWX1JSEmvpjYIFAgy//G6+vGw6OwOtGPSv61n4wGiWz/7Q79JEpB761hAxs6/MbOdBXl+Z2c5YFmhmrYluRWQCHYBmRHdH1Rrn3FPOuSznXFa7du1qc1FxI7PvMI69I5e8bhPpVL6SPu9cxKLfjGLe+3+jcm+F3+WJSD3xrSHinEt1zrU4yCvVOdcixmWeDqxxzpU45yqBN4CRQCtv9xZEL2bc4H3eAHQC8L5vSfTA/v72g8wjNSClSTNyrrqP5B8vJq/HraRXFDHki5spu78XuU/+kDVLZ/tdooj4zI9nrK8DcsysqXdsYzSwFPgY2HftyQTgLe/zNG8a7/t/evfxmgZc7p29lQn0JHoti9Swps1bknPlL2l970rmn/gE65v2ZdiXfyNz6ums+dVA8p67h1ULvyASDvtdqojUMYv+Pa7jhZr9kuitVELAPOB6osczXgbaeG1XOucqzCwF+CswBNgGXO6cW+39zr3Atd7v3Oqcm364ZWdlZbn8/PyaH1QjU7q5mMJP/kaLwrc4rnIpADtozupmQwj3HEfvUVfQolVbn6sUkZpiZnOcc1kHtPsRIn5SiNS8ki+LWJs/ncjqT+m8YxbpbGWvS2BJs2xCPcbROfsc2md097tMETkKChGPQqR2uUiElXM/YfvsV8jc/AHtKQWgKNCZTe1G0qzfmfTKPoPklKY+VyoiR0Ih4lGI1B0XiVC0bDab571L8/Wf0Kt8MUkWYo9LpqDpYMq7nErHrHPJ6NHf71JF5DAUIh6FiH/27CqjYNZ0ypfOoGPpF2S4TQAU27EUp51I077j6JVzJilNmvlcqYh8k0LEoxCpP4oLF7Mh/x+krP0nvffMI8Uq+dolsaLpUCoyR9Ml5wLSO/f0u0wRQSGyn0Kkfirfs4sVM6dTvmQ6nUo/p4PbDMCaQBc2tT+JlgPPoVfWaBISk3yuVKRxUoh4FCL1n4tEWFewkI2z/07qun/Sq2IxiRZmJ80oSM3G9RxLz5MuoWXrNL9LFWk0FCIehUjDs3NHKYW50wivmEG3HV/QljIqXZBlTYbwdfcz6T7yEtI6dPG7TJG4phDxKEQatkg4zMp5n7B9zht02vTh/oPzKxJ6s63TGWSMvJxOPQb4XKVI/FGIeBQi8WPfKcSbZr1B2oaP6BkqAGBVsBslnc6k44lXKFBEaohCxKMQiV+b1hVQ9NlLtFrzLn1CywBYFcykpNNZZJz4HV2PInIUFCIehUjjsGl9IUWfvvhfgVIY7E5Jl7PJHHWVTh0WOUIKEY9CpPGJBsoLtFnzNr1CKwFYkjSA3b0v5rjTryK1ZRufKxSp/xQiHoVI47Zh9TLW/es5MtZNo5P7knKXyJIWJ5Ew9Dv0O3G8rkMROQSFiEchIvCfG0XuyPsrvbe+Tyt2sZVWFKafTfop19L1uAP+XxFp1BQiHoWIfNPeinIWf/IqtuBF+u+eSaKFWZnQix19rqDvmGto3qK13yWK+E4h4lGIyLcp3VxMwYfPkL7qVbpG1rHHJbO4zRm0GfUDegwa6Xd5Ir5RiHgUIlId+3Z3lf37afpv+5CmVsGKhD58NfBqBo69hqTkFL9LFKlTChGPQkSOVNn2rSx770k6FLxA58gGSmhNYdfL6XP2LbRud6zf5YnUCYWIRyEisYqEwyz+9E2YOYmB5fmUu0QWpJ1F+pjb6dJ7sN/lidQqhYhHISI1Ye2yOWz+4BEGlb5HslWyoMlwEk68hb4jzsQCAb/LE6lxChGPQkRqUunmYla+8yi9171MG3ayMqEXXw39AYPHfI9gQoLf5YnUGIWIRyEitaF8zy4WvPMEHZc+TYbbyHrrwMb+NzLo7JtITmnqd3kiR00h4lGISG0Kh0Is+PBvpM7+Ez3DhWyhDWv6/oCh508kMSnZ7/JEYnaoENHOW5EaFExIYOi4q+lx72wWnfYcpYnpDF/6a7b8ZgCz33qccCjkd4kiNUohIlILLBBgwMkX0Ofuf7PglKf5OtCcYfPuZv39g5k746+4SMTvEkVqhEJEpBZZIMCgUy+h2z2zmZP9ewJEGJr7vxTcP5yludP9Lk/kqClEROpAIBjk+LOuo8Pd85k16D5ahLbRd8blzH3oXDasXuZ3eSIxU4iI1KGExCSyL5hIyzvmk9vl+/TZNZN2U04k74kfULZ9q9/liRwxhYiID5o0S2XENQ+y+6ZZLGh9BtkbXyTy6GBmvvIAocq9fpcnUm0KEREftevQlWG3vszqC9/hy6RuDF/2G9Y+kM3y/I/8Lk2kWhQiIvVAj0Ej6XvXJ8wb8UdSw2X0+sdFzPzTBO3iknpPISJST1ggwJCxE2h6+1xmpV9G1ta3qHz0eOa8+6xOCZZ6y5cQMbNWZvaamS03s2VmNsLM2pjZB2ZW4L239vqamf3RzArNbKGZDa3yOxO8/gVmNsGPsYjUtOYtWpPzP0+y5sK32RFsy/GzbmXBw2exaX2h36WJHMCvLZFHgfecc32AQcAy4C7gI+dcT+AjbxrgTKCn97oRmARgZm2AnwPDgWzg5/uCRyQe9Bh0Il3vyiOvx2303j2H5k+fyMxXHyYSDvtdmsh+dR4iZtYSOBmYDOCc2+uc2wGMB6Z43aYA53ufxwPPu6g8oJWZHQuMBT5wzm1zzm0HPgDG1eFQRGpdQmISOVf+gm0TPqUopTfDl9zHsgdH6doSqTf82BLJBEqAZ81snpk9bWbNgPbOuY1en01Ae+9zR2B9lfmLvbZDtR/AzG40s3wzyy8pKanBoYjUjY7djqPfTz5m1oBf0LmigFZTRjH773/WsRLxnR8hkgAMBSY554YAu/nPrisAXPTWwjV2e2Hn3FPOuSznXFa7du1q6mdF6pQFAmRfdBu7r/uMtck9GTb/HuY+ciFl2/QPI/GPHyFSDBQ752Z6068RDZXN3m4qvPct3vcbgE5V5s/w2g7VLhLX0jv3pPedn5DX9WYG7vyUr/84gmUzZ/hdljRSdR4izrlNwHoz6+01jQaWAtOAfWdYTQDe8j5PA67yztLKAcq83V4zgDFm1to7oD7GaxOJe8GEBHKuvp81498gZEF6vXsZuZN/pKvdpc759fzOHwIvmFkSsBq4hmigTTWz64C1wKVe33eBs4BCYI/XF+fcNjO7D5jt9fuVc25b3Q1BxH+9ho5iV4885k6+iRHrn2bZb3Npe/ULHNMx0+/SpJHQkw1F4kT+P56kb/7P+NpS2Hj6Y/Q/8Ty/S5I4oicbisS5rHNvouSK99gVaMFxH1xF7nN36ZoSqXUKEZE40qXPUNJu+5x5LUczomgSC353ju6/JbVKISISZ5qltuL4W18lr/dP6L97Jl/98UTWLJl5+BlFYqAQEYlDFgiQc8U9rDrrZZJdOe2nnkv+20/5XZbEIYWISBzrM3wMduO/WJvUg6z8O8h7/AYq91b4XZbEEYWISJxL69CFHnd8TN4xl5KzZSoFD51G6eZiv8uSOKEQEWkEEpOSyfnBX8g//rd027uCykmjWLXwC7/LkjigEBFpRLLOvYn1579BgDDHvn4+c997zu+SpIFTiIg0Mj2HnEzg+/9ifWImQ/NuIe+5e3Q3YImZQkSkEUpL70yXH/2T/BZnkFP0Z/IfvYyK8j1+lyUNkEJEpJFKadKM42+dSm6X7zOs7H1W/+50tpdsPPyMIlUoREQaMQsEGHHNg8zJ/j3d9q5k9+Onsr5wkd9lSQOiEBERjj/rOtac/RLN3G5S/zZOzyeRalOIiAgAfbLPYM9V7/GVtaD7u9/RFe5SLQoREdmvY7d+tPjfTyhMPo6s/DvIffYnOnNLvpVCRET+S8u27el++/vMbjmGEWufIP/RK9hbUe53WVJPKURE5ADJKU3JuuUVcjvfxLCy91j5+7Hs3FHqd1lSDylEROSgLBBgxLW/ZfaQ39C7fBGlfzyNzcWr/C5L6hmFiIh8q2Hjf8Dy0c/SLrwZe/p0Vi3K87skqUcUIiJyWANOHs+WS94C4NjXzmP+hy/5XJHUFwoREamWbv2HYzd+zIbEzgz87H/Ie+GXOnNLFCIiUn3tOnQl47aPmd/8JHIKfs/sP31PZ241cgoRETkiTZqlMvj2v5Pb8Wqyt79Nge651agpRETkiAWCQUbc8Cj5Qx+kR8Vy9jx+CmuWzva7LPGBQkREYpZ13vdZc+4rJLsKjn3lTGa++rCOkzQyChEROSp9skbD9z+jIGUAw5fcx7zfj6ds+1a/y5I6ohARkaOWlt6Zfnd+SF63iQz46t98/WiO7gTcSChERKRGBIJBcq66jzXj3yBsAXq9exm5k39MqHKv36VJLVKIiEiN6jV0FC1uzWNuqzMYsf4vrHrwJNatnO93WVJLFCIiUuNSW7Zh2G2vkp/1EOmh9RzzwunkvfArIuGw36VJDVOIiEityTrnRipvzGV50+PJKfgdKx84kTVLZvpdltQg30LEzIJmNs/M3vamM81sppkVmtkrZpbktSd704Xe912r/MbdXvsKMxvrz0hE5NukdejCoDumM3vw/bSvXE/G1DPJffJm9uwq889B1jwAAAqQSURBVLs0qQF+boncAiyrMv0g8IhzrgewHbjOa78O2O61P+L1w8z6ApcD/YBxwONmFqyj2kXkCFggwLDzb8b+N595bcYxYuPf+OrhIeRPe0K7uBo4X0LEzDKAs4GnvWkDTgNe87pMAc73Po/3pvG+H+31Hw+87JyrcM6tAQqB7LoZgYjEolVaOtm3vMjyM19lZ7A1WXN/QsFvRrB81gd+lyYx8mtL5A/AncC+S1vbAjuccyFvuhjo6H3uCKwH8L4v8/rvbz/IPCJSj/UZPobu98xi1qBf0za0mT7vXszCB05j+cz3/S5NjlCdh4iZnQNscc7NqcNl3mhm+WaWX1JSUleLFZFvEQgGyb7ghzT50QLyut9CRnkBfaZfwpL7T2LejCm6vqSB8GNLZCRwnpkVAS8T3Y31KNDKzBK8PhnABu/zBqATgPd9S6C0avtB5vkvzrmnnHNZzrmsdu3a1exoROSoNEttRc73fkXKjxeT1/N22u7dyJDciWz7v97kTv4xxYWL/S5RvoU55/xbuNko4MfOuXPM7FXgdefcy2b2BLDQOfe4md0MDHDOfd/MLgcudM5damb9gBeJHgfpAHwE9HTOfetRuqysLJefn1+r4xKR2IVDIRZ9PJXAnMkMLI/+v1qQ0JPSrmeTfvy5dOk9FAvo6oS6ZmZznHNZB7TXoxDpRnTLpA0wD7jSOVdhZinAX4EhwDbgcufcam/+e4FrgRBwq3Nu+uGWqRARaTg2F69izSd/JW3NNHqEVwGwhTasa3E8ofTBtMg8nk59h5Paso3Plca/ehkiflCIiDRMG9euYH3+dIJFn9Dlq3mksWP/d5tIY0tKF/a06A6tOpPUOoOm7TqT2iad5q3b06JlG229HKVDhUjCwTqLiNQ3x3bpzbFdegO3ArD1y7VsWD6TPevnk1i6kpa719Bj81s03VJxwLwhF2CXNWW3NePrQHP2BpoQCqYQDiQTCSbhLIFIIBGXkIJLaIJLbAoJyVgwEYJJWDDReyVggQQIBjELEAgmYIFoeyDBew8mEggEsf2vAIFAkEBCtD2YkEQwMZGExGQv2AwzI+j9RjAYjH4OJhAMRv9ERyJhwuEQwWACCQmJ9SoQFSIi0iCldehCWocuwKX721wkQtn2ErZ+uYZdJUXs3bmV8O5S3J5tBCp2Ety7k4TKXSSGvyY59BVJkRISXCVBwiS4ShIJkewqaGoHBpGfgkBilem9LoEQQUIWJEKAMFXeLRpMDnAEcNj+tvQ7Z5Gc0rRGa1OIiEjcsECAlm3b07JteyAn5t+JhMPs3VtOqHIvob0VhEJ7CVXuJVxZSSS8l0jE4SIhwqEQkXAlkVBl9D0cxoUriYRDOBcBF8aFI0QiYVw4hHMhXKgSwtH+uAi46J97FwlDJAyRUPSzC0MkAmbeKxDtH66E0F4sUgkujEVC3nsYXARzIcz7TZyLxomLYEToEKj5m3ooREREviEQDJLSpBk0aeZ3KfVe/dmxJiIiDY5CREREYqYQERGRmClEREQkZgoRERGJmUJERERiphAREZGYKURERCRmje4GjGZWAqyNcfY0YGsNltMQNMYxQ+Mcd2McMzTOcccy5i7OuQMeyNToQuRomFn+we5iGc8a45ihcY67MY4ZGue4a3LM2p0lIiIxU4iIiEjMFCJH5im/C/BBYxwzNM5xN8YxQ+Mcd42NWcdEREQkZtoSERGRmClEREQkZgqRajCzcWa2wswKzewuv+upLWbWycw+NrOlZrbEzG7x2tuY2QdmVuC9t/a71ppmZkEzm2dmb3vTmWY201vnr5hZkt811jQza2Vmr5nZcjNbZmYj4n1dm9lt3n/bi83sJTNLicd1bWbPmNkWM1tcpe2g69ai/uiNf6GZDT2SZSlEDsPMgsCfgTOBvsAVZtbX36pqTQj4kXOuL9Fni97sjfUu4CPnXE/gI2863twCLKsy/SDwiHOuB7AduM6XqmrXo8B7zrk+wCCi44/bdW1mHYGJQJZzrj/RR5dfTnyu6+eAcd9oO9S6PRPo6b1uBCYdyYIUIoeXDRQ651Y75/YCLwPjfa6pVjjnNjrn5nqfvyL6R6Uj0fFO8bpNAc73p8LaYWYZwNnA0960AacBr3ld4nHMLYGTgckAzrm9zrkdxPm6JvpI8CZmlgA0BTYSh+vaOfcpsO0bzYdat+OB511UHtDKzI6t7rIUIofXEVhfZbrYa4trZtYVGALMBNo75zZ6X20C2vtUVm35A3AnEPGm2wI7nHMhbzoe13kmUAI86+3Ge9rMmhHH69o5twF4GFhHNDzKgDnE/7re51Dr9qj+xilE5ABm1hx4HbjVObez6ncuek543JwXbmbnAFucc3P8rqWOJQBDgUnOuSHAbr6x6yoO13Vrov/qzgQ6AM04cJdPo1CT61YhcngbgE5VpjO8trhkZolEA+QF59wbXvPmfZu33vsWv+qrBSOB88ysiOiuytOIHito5e3ygPhc58VAsXNupjf9GtFQied1fTqwxjlX4pyrBN4guv7jfV3vc6h1e1R/4xQihzcb6OmdwZFE9EDcNJ9rqhXesYDJwDLn3O+rfDUNmOB9ngC8Vde11Rbn3N3OuQznXFei6/afzrnvAh8DF3vd4mrMAM65TcB6M+vtNY0GlhLH65robqwcM2vq/be+b8xxva6rONS6nQZc5Z2llQOUVdntdVi6Yr0azOwsovvNg8Azzrn/87mkWmFmJwKfAYv4z/GBe4geF5kKdCZ6G/1LnXPfPGjX4JnZKODHzrlzzKwb0S2TNsA84ErnXIWf9dU0MxtM9GSCJGA1cA3Rf1jG7bo2s18ClxE9E3EecD3R/f9xta7N7CVgFNFbvm8Gfg78nYOsWy9QHyO6a28PcI1zLr/ay1KIiIhIrLQ7S0REYqYQERGRmClEREQkZgoRERGJmUJERERiphARqefMbNS+uwuL1DcKERERiZlCRKSGmNmVZjbLzOab2ZPeM0p2mdkj3jMsPjKzdl7fwWaW5z2/4c0qz3boYWYfmtkCM5trZt29n29e5dkfL3gXiGFmD1j0+S8Lzexhn4YujZhCRKQGmNlxRK+EHumcGwyEge8SvclfvnOuH/AvolcOAzwP/MQ5N5DoHQL2tb8A/Nk5Nwg4gejdZiF6R+VbiT7Tphsw0szaAhcA/bzf+XXtjlLkQAoRkZoxGjgemG1m873pbkRvH/OK1+dvwIneszxaOef+5bVPAU42s1Sgo3PuTQDnXLlzbo/XZ5Zzrtg5FwHmA12J3sq8HJhsZhcSvWWFSJ1SiIjUDAOmOOcGe6/ezrlfHKRfrPcZqnovpzCQ4D0DI5voHXjPAd6L8bdFYqYQEakZHwEXm9kxsP951l2I/j+27w6x3wE+d86VAdvN7CSv/XvAv7ynSRab2fnebySbWdNDLdB77ktL59y7wG1EH3ErUqcSDt9FRA7HObfUzH4KvG9mAaASuJnow56yve+2ED1uAtFbcT/hhcS+O+hCNFCeNLNfeb9xybcsNhV4y8xSiG4J3V7DwxI5LN3FV6QWmdku51xzv+sQqS3anSUiIjHTloiIiMRMWyIiIhIzhYiIiMRMISIiIjFTiIiISMwUIiIiErP/DxDOPHatrQxBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExBaSFFnFMnN"
      },
      "source": [
        "#remember that normalization doesn't gaurentee reduction in mae, it's simply a metric to follow to make sure your data is precived correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scYIcCotG9Au"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}